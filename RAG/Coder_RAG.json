[
    {
        "requirement": "def read_image(file_path: str):\n    '''\n    This function will handle reading the image using the `cv2.imread()` function in BGR format.\n    ARGUMENTS:\n    - file_path: str : The path to the image file that needs to be read.\n    \n    RETURN: \n    - image: numpy.ndarray : The read image in BGR format.\n    '''\n    # TODO: Use cv2.imread() to read the image from the specified file path\n    image = cv2.imread(file_path)\n    return image\n",
        "answer": "'''\nThis function will handle reading the image using the `cv2.imread()` function in BGR format.\nARGUMENTS:\n- file_path: str : The path to the image file that needs to be read.\n\nRETURN: \n- image: numpy.ndarray : The read image in BGR format.\n'''\nimport cv2\n\ndef read_image(file_path: str):\n    image = cv2.imread(file_path)\n    return image"
    },
    {
        "requirement": "def convert_bgr_to_rgb(image: numpy.ndarray):\n    '''\n    This function will manipulate the image data to convert the BGR format to RGB format by swapping the channels.\n    ARGUMENTS:\n    - image: numpy.ndarray : The input image in BGR format that needs to be converted.\n    \n    RETURN: \n    - rgb_image: numpy.ndarray : The converted image in RGB format.\n    '''\n    # TODO: Swap the channels of the BGR image to convert it to RGB\n    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return rgb_image\n",
        "answer": "'''\nThis function will manipulate the image data to convert the BGR format to RGB format by swapping the channels.\nARGUMENTS:\n- image: numpy.ndarray : The input image in BGR format that needs to be converted.\n\nRETURN: \n- rgb_image: numpy.ndarray : The converted image in RGB format.\n'''\nimport numpy as np\nimport cv2\n\ndef convert_bgr_to_rgb(image: np.ndarray):\n    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return rgb_image"
    },
    {
        "requirement": "def save_image(image: numpy.ndarray, save_path: str):\n    '''\n    This function will save the manipulated image data back to the disk in the desired file format.\n    ARGUMENTS:\n    - image: numpy.ndarray : The image data that needs to be saved to disk.\n    - save_path: str : The file path where the image will be saved.\n    \n    RETURN: \n    - None\n    '''\n    # TODO: Use cv2.imwrite() to save the image to the specified file path\n    cv2.imwrite(save_path, image)\n```\n\nThese pseudo codes effectively cover the requirement for reading an image in BGR format, converting it to RGB by swapping the channels, and saving the resulting image, as outlined by the Module Leader's specifications.",
        "answer": "'''\nThis function will save the manipulated image data back to the disk in the desired file format.\nARGUMENTS:\n- image: numpy.ndarray : The image data that needs to be saved to disk.\n- save_path: str : The file path where the image will be saved.\n\nRETURN: \n- None\n'''\ndef save_image(image: numpy.ndarray, save_path: str):\n    import cv2\n    cv2.imwrite(save_path, image)"
    },
    {
        "requirement": "def convert_to_grayscale(image: numpy.ndarray) -> numpy.ndarray:\n    '''\n    Convert the loaded color image to grayscale using OpenCV's cvtColor function.\n    ARGUMENTS: \n    - image: numpy.ndarray - The color image as a NumPy array that needs to be converted.\n    RETURN: numpy.ndarray - The converted grayscale image as a NumPy array.\n    '''\n    # TODO: Perform conversion to grayscale using cv2.cvtColor() and return the grayscale image\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return gray_image\n",
        "answer": "'''\nConvert the loaded color image to grayscale using OpenCV's cvtColor function.\nARGUMENTS: \n- image: numpy.ndarray - The color image as a NumPy array that needs to be converted.\nRETURN: numpy.ndarray - The converted grayscale image as a NumPy array.\n'''\nimport cv2\nimport numpy\n\ndef convert_to_grayscale(image: numpy.ndarray) -> numpy.ndarray:\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return gray_image"
    },
    {
        "requirement": "def binarize_image(gray_image: np.ndarray) -> np.ndarray:\n    '''\n    Convert the loaded grayscale image to a binary image using the threshold of 128.\n    ARGUMENTS: \n    gray_image: np.ndarray - The grayscale image as a NumPy array.\n    \n    RETURN: \n    np.ndarray - The resulting binary image as a NumPy array.\n    '''\n    # Apply thresholding to create a binary image\n    _, binary_image = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY)\n    return binary_image\n",
        "answer": "'''\nConvert the loaded grayscale image to a binary image using the threshold of 128.\nARGUMENTS: \ngray_image: np.ndarray - The grayscale image as a NumPy array.\n\nRETURN: \nnp.ndarray - The resulting binary image as a NumPy array.\n'''\ndef binarize_image(gray_image: np.ndarray) -> np.ndarray:\n    # Apply thresholding to create a binary image\n    _, binary_image = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY)\n    return binary_image"
    },
    {
        "requirement": "def CALCULATE_HISTOGRAM(image: np.ndarray) -> np.ndarray:\n    '''\n    This function will compute the histogram of the input image to analyze the pixel intensity distribution, which is essential for determining the optimal threshold.\n    ARGUMENTS: image: An input image represented as a NumPy array.\n    RETURN: A normalized histogram represented as a NumPy array.\n    '''\n    # TODO: Calculate and return the histogram of the image using cv2.calcHist\n\n",
        "answer": "'''\nThis function will compute the histogram of the input image to analyze the pixel intensity distribution, which is essential for determining the optimal threshold.\nARGUMENTS: image: An input image represented as a NumPy array.\nRETURN: A normalized histogram represented as a NumPy array.\n'''\nimport cv2\nimport numpy as np\n\ndef CALCULATE_HISTOGRAM(image: np.ndarray) -> np.ndarray:\n    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n    normalized_hist = hist / hist.sum()  # Normalize the histogram\n    return normalized_hist.flatten()  # Return as a flattened array"
    },
    {
        "requirement": "def CALCULATE_INTRACLASS_VARIANCE(histogram: np.ndarray, total_pixels: int) -> np.ndarray:\n    '''\n    This function will calculate the intra-class variance for different threshold values based on the histogram data, which helps in assessing the compactness of the clusters formed by the thresholding.\n    ARGUMENTS: histogram: A normalized histogram of the image as a NumPy array; total_pixels: The total number of pixels in the input image.\n    RETURN: An array of intra-class variances for each threshold value.\n    '''\n    # TODO: Calculate and return the intra-class variance for each threshold\n\n",
        "answer": "'''\nThis function will calculate the intra-class variance for different threshold values based on the histogram data, which helps in assessing the compactness of the clusters formed by the thresholding.\nARGUMENTS: histogram: A normalized histogram of the image as a NumPy array; total_pixels: The total number of pixels in the input image.\nRETURN: An array of intra-class variances for each threshold value.\n'''\nimport numpy as np\n\ndef CALCULATE_INTRACLASS_VARIANCE(histogram: np.ndarray, total_pixels: int) -> np.ndarray:\n    total_weight = np.cumsum(histogram)  # Cumulative histogram (weight)\n    total_sum = np.cumsum(histogram * np.arange(len(histogram)))  # Cumulative sum of pixel values\n\n    intra_class_variance = np.zeros(len(histogram))  # Initialize array for intra-class variance\n\n    for t in range(1, len(histogram)):  # Iterate through all possible thresholds\n        if total_weight[t] == 0 or total_weight[-1] == 0:\n            continue  # Prevent division by zero\n\n        weight_background = total_weight[t]  # Weight of the background\n        weight_foreground = total_weight[-1] - weight_background  # Weight of the foreground\n\n        mean_background = total_sum[t] / weight_background if weight_background > 0 else 0  # Mean of the background\n        mean_foreground = (total_sum[-1] - total_sum[t]) / weight_foreground if weight_foreground > 0 else 0  # Mean of the foreground\n\n        # Intra-class variance\n        intra_class_variance[t] = (\n            weight_background * (mean_background - np.mean(histogram * np.arange(len(histogram)))) ** 2 +\n            weight_foreground * (mean_foreground - np.mean(histogram * np.arange(len(histogram)))) ** 2\n        )\n\n    return intra_class_variance"
    },
    {
        "requirement": "def CALCULATE_INTERCLASS_VARIANCE(histogram: np.ndarray, total_pixels: int) -> np.ndarray:\n    '''\n    This function will compute the inter-class variance for different threshold values, allowing for evaluation of the separation between the two classes (foreground and background).\n    ARGUMENTS: histogram: A normalized histogram of the image as a NumPy array; total_pixels: The total number of pixels in the input image.\n    RETURN: An array of inter-class variances for each threshold value.\n    '''\n    # TODO: Calculate and return the inter-class variance for each threshold\n\n",
        "answer": "'''\nThis function will compute the inter-class variance for different threshold values, allowing for evaluation of the separation between the two classes (foreground and background).\nARGUMENTS: histogram: A normalized histogram of the image as a NumPy array; total_pixels: The total number of pixels in the input image.\nRETURN: An array of inter-class variances for each threshold value.\n'''\nimport numpy as np\n\ndef CALCULATE_INTERCLASS_VARIANCE(histogram: np.ndarray, total_pixels: int) -> np.ndarray:\n    if total_pixels == 0:\n        return np.array([])  # Avoid division by zero\n\n    inter_class_variance = np.zeros(len(histogram))\n    cumulative_sum = np.cumsum(histogram)\n    cumulative_mean = np.cumsum(histogram * np.arange(len(histogram)))\n\n    for threshold in range(len(histogram)):\n        if cumulative_sum[threshold] > 0 and cumulative_sum[threshold] < total_pixels:\n            # Calculate the class probabilities\n            p1 = cumulative_sum[threshold]\n            p2 = total_pixels - p1\n\n            # Calculate the means\n            mean1 = cumulative_mean[threshold] / p1 if p1 > 0 else 0\n            mean2 = (cumulative_mean[-1] - cumulative_mean[threshold]) / p2 if p2 > 0 else 0\n\n            # Calculate inter-class variance\n            inter_class_variance[threshold] = p1 * p2 * (mean1 - mean2) ** 2\n\n    return inter_class_variance"
    },
    {
        "requirement": "def FIND_OPTIMAL_THRESHOLD(intra_class_var: np.ndarray, inter_class_var: np.ndarray) -> int:\n    '''\n    This function will determine the optimal threshold value using the calculated intra-class and inter-class variances, identifying the threshold that minimizes intra-class variance or maximizes inter-class variance.\n    ARGUMENTS: intra_class_var: An array of intra-class variances; inter_class_var: An array of inter-class variances.\n    RETURN: The optimal threshold value as an integer.\n    '''\n    # TODO: Implement the logic to find and return the optimal threshold\n\n",
        "answer": "'''\nThis function will determine the optimal threshold value using the calculated intra-class and inter-class variances, identifying the threshold that minimizes intra-class variance or maximizes inter-class variance.\nARGUMENTS: intra_class_var: An array of intra-class variances; inter_class_var: An array of inter-class variances.\nRETURN: The optimal threshold value as an integer.\n'''\nimport numpy as np\n\ndef FIND_OPTIMAL_THRESHOLD(intra_class_var: np.ndarray, inter_class_var: np.ndarray) -> int:\n    # Find the index of the minimum intra-class variance\n    optimal_intra_idx = np.argmin(intra_class_var)\n    # Find the index of the maximum inter-class variance\n    optimal_inter_idx = np.argmax(inter_class_var)\n    \n    # Choose the threshold that minimizes the intra-class variance or maximizes the inter-class variance\n    # You may decide to take the one that is more relevant for your application\n    # Here we return the one that gives a numerical value of stability in case of equal variances\n    if optimal_intra_idx == optimal_inter_idx:\n        return optimal_intra_idx  # or optimal_inter_idx, they are the same\n    \n    # Otherwise, return the one that has the lowest intra-class variance\n    return optimal_intra_idx"
    },
    {
        "requirement": "def BINARIZE_IMAGE(image: np.ndarray, threshold: int) -> np.ndarray:\n    '''\n    This function will apply the optimal threshold to the original image to produce the binarized output image.\n    ARGUMENTS: image: An input image represented as a NumPy array; threshold: The threshold value for binarization.\n    RETURN: The binarized image as a NumPy array.\n    '''\n    # TODO: Apply thresholding to the image using NumPy operations and return the binarized image\n```\n\nThese definitions set a clear format for implementing the functions that will constitute the OTSU_BINARIZATION module. Make sure that the development groups confirm the use of `numpy` and `cv2` libraries for handling image processing tasks and data manipulation.",
        "answer": "'''\nThis function will apply the optimal threshold to the original image to produce the binarized output image.\nARGUMENTS: image: An input image represented as a NumPy array; threshold: The threshold value for binarization.\nRETURN: The binarized image as a NumPy array.\n'''\nimport numpy as np\n\ndef BINARIZE_IMAGE(image: np.ndarray, threshold: int) -> np.ndarray:\n    # Apply thresholding to binarize the image\n    # Pixels below the threshold will be set to 0 (black), and above to 255 (white)\n    binarized_image = np.where(image > threshold, 255, 0).astype(np.uint8)\n    return binarized_image"
    },
    {
        "requirement": "def NORMALIZE_IMAGE(image: np.ndarray) -> np.ndarray:\n    '''\n    This function will normalize the pixel values of the grayscale image to ensure that they are in the range suitable for thresholding (typically 0 to 1 or 0 to 255).\n    ARGUMENTS:\n    - image: np.ndarray - The grayscale image in NumPy array format.\n    RETURN: \n    - np.ndarray - The normalized image in NumPy array format.\n    '''\n    # Normalize the image to values between 0 and 1\n    normalized_image = image / 255.0\n    return normalized_image\n",
        "answer": "'''\nThis function will normalize the pixel values of the grayscale image to ensure that they are in the range suitable for thresholding (typically 0 to 1 or 0 to 255).\nARGUMENTS:\n- image: np.ndarray - The grayscale image in NumPy array format.\nRETURN: \n- np.ndarray - The normalized image in NumPy array format.\n'''\nimport numpy as np\n\ndef NORMALIZE_IMAGE(image: np.ndarray) -> np.ndarray:\n    # Ensure that the image is of type float32 for proper normalization\n    image = image.astype(np.float32)\n    # Normalize the image to values between 0 and 1\n    normalized_image = image / 255.0\n    return normalized_image"
    },
    {
        "requirement": "def PREPARE_FOR_BINARIZATION(image: np.ndarray, target_size: tuple = (256, 256)) -> np.ndarray:\n    '''\n    This function will execute any additional necessary preprocessing steps, such as resizing or filtering, to prepare the image for the Otsu binarization.\n    ARGUMENTS:\n    - image: np.ndarray - The normalized grayscale image in NumPy array format.\n    - target_size: tuple - The target size for resizing the image (default is (256, 256)).\n    RETURN: \n    - np.ndarray - The preprocessed image ready for binarization.\n    '''\n    # Resize the image and return as a NumPy array\n    prep_image = Image.fromarray((image * 255).astype(np.uint8)).resize(target_size)\n    return np.array(prep_image)\n```\n\nThese pseudo code definitions outline the functions that are required for the IMAGE_PREPROCESSING module, providing details on the function purpose, arguments, and return types, as well as stipulating the use of the Pillow library (PIL) and NumPy for image manipulation.",
        "answer": "'''\nThis function will execute any additional necessary preprocessing steps, such as resizing or filtering, to prepare the image for the Otsu binarization.\nARGUMENTS:\n- image: np.ndarray - The normalized grayscale image in NumPy array format.\n- target_size: tuple - The target size for resizing the image (default is (256, 256)).\nRETURN: \n- np.ndarray - The preprocessed image ready for binarization.\n'''\ndef PREPARE_FOR_BINARIZATION(image: np.ndarray, target_size: tuple = (256, 256)) -> np.ndarray:\n    from PIL import Image\n    import numpy as np\n    \n    # Resize the image and return as a NumPy array\n    prep_image = Image.fromarray((image * 255).astype(np.uint8)).resize(target_size)\n    return np.array(prep_image)"
    },
    {
        "requirement": "def rgb_to_hsv(img_file: str) -> np.ndarray:\n    '''\n    Converts RGB image to HSV.\n    ARGUMENTS: \n    img_file: str - Image file path.\n    RETURN: \n    np.ndarray - image 2D array of color values (H, S, V) where H is in the range [0, 1], S and V are in the range [0, 1].\n    '''\n    # Convert RGB to [0, 1] range\n    r, g, b = [x / 255.0 for x in rgb]\n    return colorsys.rgb_to_hsv(r, g, b)\n",
        "answer": "'''\nConverts RGB image to HSV.\nARGUMENTS: \nimg_file: str - Image file path.\nRETURN: \nnp.ndarray - image 2D array of color values (H, S, V) where H is in the range [0, 1], S and V are in the range [0, 1].\n'''\nimport numpy as np\nfrom PIL import Image\nimport colorsys\n\ndef rgb_to_hsv(img_file: str) -> np.ndarray:\n    # Load the image\n    img = Image.open(img_file)\n    img = img.convert('RGB')  # Ensure the image is in RGB format\n\n    # Convert the image to a numpy array\n    rgb_array = np.array(img) / 255.0  # Normalize to [0, 1]\n    \n    # Prepare an output array for HSV\n    hsv_array = np.zeros_like(rgb_array)\n\n    # Convert each pixel from RGB to HSV\n    for i in range(rgb_array.shape[0]):\n        for j in range(rgb_array.shape[1]):\n            r, g, b = rgb_array[i, j]\n            h, s, v = colorsys.rgb_to_hsv(r, g, b)\n            hsv_array[i, j] = [h, s, v]\n    \n    return hsv_array"
    },
    {
        "requirement": "def hsv_to_rgb(img:np.ndarray) -> np.ndarray:\n    '''\n    Converts HSV image back to RGB.\n    ARGUMENTS: \n    img - A 2D image array of HSV color values (H, S, V) where H is in the range [0, 1], S and V are in the range [0, 1].\n    RETURN: \n    np.array - An image 2D array in RGB color values (R, G, B) where each value is in the range [0, 255].\n    '''\n    r, g, b = colorsys.hsv_to_rgb(*hsv)\n    return (int(r * 255), int(g * 255), int(b * 255))\n",
        "answer": "'''\nConverts HSV image back to RGB.\nARGUMENTS: \nimg - A 2D image array of HSV color values (H, S, V) where H is in the range [0, 1], S and V are in the range [0, 1].\nRETURN: \nnp.array - An image 2D array in RGB color values (R, G, B) where each value is in the range [0, 255].\n'''\nimport numpy as np\nimport colorsys\n\ndef hsv_to_rgb(img: np.ndarray) -> np.ndarray:\n    # Ensure the input image is of the correct shape\n    if img.ndim != 3 or img.shape[2] != 3:\n        raise ValueError(\"Input image must be a 3D array with the last dimension size of 3 (H, S, V).\")\n    \n    # Initialize an empty array for the RGB output\n    rgb_image = np.zeros_like(img, dtype=np.uint8)\n\n    for i in range(img.shape[0]):\n        for j in range(img.shape[1]):\n            hsv = img[i, j]\n            r, g, b = colorsys.hsv_to_rgb(hsv[0], hsv[1], hsv[2])\n            rgb_image[i, j] = (int(r * 255), int(g * 255), int(b * 255))\n\n    return rgb_image"
    },
    {
        "requirement": "def flip_hue(img:np.ndarray) -> np.ndarray:\n    '''\n    Flips the Hue value of the given HSV input image.\n    ARGUMENTS: \n    img:np.ndarray - A 2D image array in HSV color values (H, S, V) where H is in the range [0, 1].\n    RETURN: \n    np.ndarray - A tuple representing modified HSV color values with the flipped Hue while Saturation and Value remain unchanged.\n    '''\n    h, s, v = hsv\n    flipped_hue = (h + 0.5) % 1.0  # Flipping Hue\n    return (flipped_hue, s, v)\n",
        "answer": "'''\nFlips the Hue value of the given HSV input image.\nARGUMENTS: \nimg:np.ndarray - A 2D image array in HSV color values (H, S, V) where H is in the range [0, 1].\nRETURN: \nnp.ndarray - A tuple representing modified HSV color values with the flipped Hue while Saturation and Value remain unchanged.\n'''\nimport numpy as np\n\ndef flip_hue(img: np.ndarray) -> np.ndarray:\n    # Ensure that the input image is in float format\n    img = img.astype(np.float32)\n    \n    # Extract H, S, V channels\n    h, s, v = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n    \n    # Flipping Hue\n    flipped_hue = (h + 0.5) % 1.0\n    \n    # Create output HSV image\n    flipped_img = np.zeros_like(img)\n    flipped_img[:, :, 0] = flipped_hue  # Update Hue\n    flipped_img[:, :, 1] = s            # Keep Saturation unchanged\n    flipped_img[:, :, 2] = v            # Keep Value unchanged\n    \n    return flipped_img"
    },
    {
        "requirement": "def quantize_color(image: numpy.ndarray) -> numpy.ndarray:\n    '''\n    This function will take the RGB values from the image and map them to the nearest quantized values based on the specified set {32, 96, 160, 224}.\n    ARGUMENTS: \n        image: numpy.ndarray - The input image as a 3D array of RGB values.\n    RETURN: \n        numpy.ndarray - The quantized image as a 3D array of RGB values.\n    '''\n    import numpy as np\n    \n    # TODO: Implement the quantization logic to map RGB values to nearest quantized values\n```\n\n### Function 3: write_image\n\n```python",
        "answer": "'''\nThis function will take the RGB values from the image and map them to the nearest quantized values based on the specified set {32, 96, 160, 224}.\nARGUMENTS: \n    image: numpy.ndarray - The input image as a 3D array of RGB values.\nRETURN: \n    numpy.ndarray - The quantized image as a 3D array of RGB values.\n'''\ndef quantize_color(image: numpy.ndarray) -> numpy.ndarray:\n    import numpy as np\n    \n    # Define the quantization values\n    quantization_values = np.array([32, 96, 160, 224])\n    \n    # Function to quantize a single color channel value\n    def quantize_value(value):\n        return quantization_values[np.argmin(np.abs(quantization_values - value))]\n    \n    # Apply the quantization to each channel of the image\n    quantized_image = np.zeros_like(image)\n    for channel in range(image.shape[2]):\n        quantized_image[..., channel] = np.vectorize(quantize_value)(image[..., channel])\n    \n    return quantized_image"
    },
    {
        "requirement": "def divide_into_grids(image: Image.Image, grid_size: int) -> list:\n    '''\n    This function will divide the loaded image into fixed-length grids (regions)\n    based on the specified grid size, returning a list of grid regions for further processing.\n\n    ARGUMENTS:\n    image: Image.Image - The image to be divided into grids.\n    grid_size: int - The size of each grid region.\n    \n    RETURN:\n    list - A list of grid regions as numpy arrays.\n    '''\n    # TODO: Implement grid division logic\n    width, height = image.size\n    grids = []\n    for i in range(0, height, grid_size):\n        for j in range(0, width, grid_size):\n            box = (j, i, min(j + grid_size, width), min(i + grid_size, height))\n            grid = image.crop(box)\n            grids.append(np.array(grid))\n    return grids\n\n",
        "answer": "'''\nThis function will divide the loaded image into fixed-length grids (regions)\nbased on the specified grid size, returning a list of grid regions for further processing.\n\nARGUMENTS:\nimage: Image.Image - The image to be divided into grids.\ngrid_size: int - The size of each grid region.\n\nRETURN:\nlist - A list of grid regions as numpy arrays.\n'''\ndef divide_into_grids(image: Image.Image, grid_size: int) -> list:\n    width, height = image.size\n    grids = []\n    for i in range(0, height, grid_size):\n        for j in range(0, width, grid_size):\n            box = (j, i, min(j + grid_size, width), min(i + grid_size, height))\n            grid = image.crop(box)\n            grids.append(np.array(grid))\n    return grids"
    },
    {
        "requirement": "def calculate_average_pooling(grids: list) -> list:\n    '''\n    This function will compute the average value for each grid region obtained\n    from the divide_into_grids function, returning a list or array of the average values.\n\n    ARGUMENTS:\n    grids: list - A list of grid regions as numpy arrays.\n    \n    RETURN:\n    list - A list of average values for each grid.\n    '''\n    # TODO: Implement average pooling calculation logic\n    averages = [np.mean(grid) for grid in grids]\n    return averages\n\n",
        "answer": "'''\nThis function will compute the average value for each grid region obtained\nfrom the divide_into_grids function, returning a list or array of the average values.\n\nARGUMENTS:\ngrids: list - A list of grid regions as numpy arrays.\n\nRETURN:\nlist - A list of average values for each grid.\n'''\nimport numpy as np\n\ndef calculate_average_pooling(grids: list) -> list:\n    averages = [np.mean(grid) for grid in grids]\n    return averages"
    },
    {
        "requirement": "def create_pooled_image(average_values: list, grid_size: int, original_image: Image.Image) -> Image.Image:\n    '''\n    This function will generate a new image (or a representation) filled with the computed\n    average values from the calculate_average_pooling function, effectively creating\n    the pooled image output.\n\n    ARGUMENTS:\n    average_values: list - A list of average values for each grid.\n    grid_size: int - The size of each grid region for correct placement.\n    original_image: Image.Image - The original image, to derive dimensions from.\n    \n    RETURN:\n    Image.Image - A new image representing the pooled output.\n    '''\n    # TODO: Implement pooled image generation logic\n    width, height = original_image.size\n    pooled_image = Image.new('L', (width, height))\n    \n    index = 0\n    for i in range(0, height, grid_size):\n        for j in range(0, width, grid_size):\n            box = (j, i, min(j + grid_size, width), min(i + grid_size, height))\n            average_value = average_values[index]\n            pooled_image.paste(Image.new('L', (grid_size, grid_size), color=int(average_value)), box)\n            index += 1\n    \n    return pooled_image\n```\n\nThese functions are structured to meet the requirement of the ImageProcessingModule. The `PIL` library is used for image manipulation, and `numpy` is used for numerical operations.",
        "answer": "'''\nThis function will generate a new image (or a representation) filled with the computed\naverage values from the calculate_average_pooling function, effectively creating\nthe pooled image output.\n\nARGUMENTS:\naverage_values: list - A list of average values for each grid.\ngrid_size: int - The size of each grid region for correct placement.\noriginal_image: Image.Image - The original image, to derive dimensions from.\n\nRETURN:\nImage.Image - A new image representing the pooled output.\n'''\ndef create_pooled_image(average_values: list, grid_size: int, original_image: Image.Image) -> Image.Image:\n    width, height = original_image.size\n    pooled_image = Image.new('L', (width, height))\n    \n    index = 0\n    for i in range(0, height, grid_size):\n        for j in range(0, width, grid_size):\n            box = (j, i, min(j + grid_size, width), min(i + grid_size, height))\n            average_value = average_values[index]\n            pooled_image.paste(Image.new('L', (grid_size, grid_size), color=int(average_value)), box)\n            index += 1\n    \n    return pooled_image"
    },
    {
        "requirement": "def define_grid_dimensions(image_width: int, image_height: int, grid_size: int):\n    '''\n    This function will take the image dimensions and the desired grid size as input \n    and calculate the number of grids needed in both dimensions (width and height).\n    \n    ARGUMENTS: \n    - image_width: int - The width of the input image.\n    - image_height: int - The height of the input image.\n    - grid_size: int - The size of each grid (assumed to be square).\n    \n    RETURN: \n    - tuple: (num_grids_width: int, num_grids_height: int) - The number of grids \n    in the width and height dimensions.\n    '''\n    # TODO\n```\n\n2. **Function Name: apply_max_pooling**\n```python",
        "answer": "'''\nThis function will take the image dimensions and the desired grid size as input \nand calculate the number of grids needed in both dimensions (width and height).\n\nARGUMENTS: \n- image_width: int - The width of the input image.\n- image_height: int - The height of the input image.\n- grid_size: int - The size of each grid (assumed to be square).\n\nRETURN: \n- tuple: (num_grids_width: int, num_grids_height: int) - The number of grids \nin the width and height dimensions.\n'''\ndef define_grid_dimensions(image_width: int, image_height: int, grid_size: int):\n    num_grids_width = (image_width + grid_size - 1) // grid_size\n    num_grids_height = (image_height + grid_size - 1) // grid_size\n    return (num_grids_width, num_grids_height)"
    },
    {
        "requirement": "def apply_max_pooling(image: np.ndarray, grid_dimensions: tuple):\n    '''\n    This function will take the input image and the grid dimensions, iterate over \n    the image grid, and calculate the maximum value for each grid region, returning \n    a pooled image.\n    \n    ARGUMENTS: \n    - image: np.ndarray - The input image to be pooled (as a NumPy array).\n    - grid_dimensions: tuple - A tuple containing (num_grids_width: int, num_grids_height: int).\n    \n    RETURN: \n    - np.ndarray - The pooled image after applying max pooling.\n    '''\n    # TODO\n```\n\n3. **Function Name: load_image**\n```python",
        "answer": "'''\nThis function will take the input image and the grid dimensions, iterate over \nthe image grid, and calculate the maximum value for each grid region, returning \na pooled image.\n\nARGUMENTS: \n- image: np.ndarray - The input image to be pooled (as a NumPy array).\n- grid_dimensions: tuple - A tuple containing (num_grids_width: int, num_grids_height: int).\n  \nRETURN: \n- np.ndarray - The pooled image after applying max pooling.\n'''\nimport numpy as np\n\ndef apply_max_pooling(image: np.ndarray, grid_dimensions: tuple) -> np.ndarray:\n    num_grids_width, num_grids_height = grid_dimensions\n    \n    # Calculate the dimensions of each grid section\n    grid_height = image.shape[0] // num_grids_height\n    grid_width = image.shape[1] // num_grids_width\n    \n    pooled_image = np.zeros((num_grids_height, num_grids_width))\n    \n    for i in range(num_grids_height):\n        for j in range(num_grids_width):\n            # Determine the section of the image that corresponds to the current grid\n            start_i = i * grid_height\n            end_i = (i + 1) * grid_height\n            start_j = j * grid_width\n            end_j = (j + 1) * grid_width\n            \n            # Select the grid section and calculate the maximum value\n            grid_section = image[start_i:end_i, start_j:end_j]\n            pooled_image[i, j] = np.max(grid_section)\n    \n    return pooled_image"
    },
    {
        "requirement": "def generate_gaussian_kernel(sigma: float):\n    '''\n    This function will create a 3x3 Gaussian kernel based on a specified standard deviation.\n    The kernel will contain the weights used for smoothing the pixels in the image.\n    \n    ARGUMENTS:\n    sigma: float - The standard deviation that determines the width of the Gaussian bell curve.\n    \n    RETURN: np.ndarray - A 3x3 array containing the Gaussian kernel.\n    '''\n    # TODO: Implement the Gaussian kernel generation logic.\n",
        "answer": "'''\nThis function will create a 3x3 Gaussian kernel based on a specified standard deviation.\nThe kernel will contain the weights used for smoothing the pixels in the image.\n\nARGUMENTS:\nsigma: float - The standard deviation that determines the width of the Gaussian bell curve.\n\nRETURN: np.ndarray - A 3x3 array containing the Gaussian kernel.\n'''\nimport numpy as np\n\ndef generate_gaussian_kernel(sigma: float):\n    size = 3  # Define the size of the kernel\n    kernel = np.zeros((size, size))  # Initialize the kernel with zeros\n    mean = size // 2  # Mean (center) of the kernel\n\n    # Calculate the Gaussian kernel\n    for x in range(size):\n        for y in range(size):\n            kernel[x, y] = (1 / (2 * np.pi * sigma ** 2)) * \\\n                           np.exp(-((x - mean) ** 2 + (y - mean) ** 2) / (2 * sigma ** 2))\n\n    # Normalize the kernel to ensure the sum is 1\n    kernel /= np.sum(kernel)\n    \n    return kernel"
    },
    {
        "requirement": "def apply_gaussian_filter(image: np.ndarray, kernel: np.ndarray):\n    '''\n    This function will take an image and the Gaussian kernel as inputs.\n    It will process the image by applying the Gaussian filter, smoothing the pixel values and effectively reducing noise.\n    \n    ARGUMENTS:\n    image: np.ndarray - The input image on which to apply the Gaussian filter.\n    kernel: np.ndarray - The Gaussian kernel to use for smoothing.\n    \n    RETURN: np.ndarray - The filtered image after applying the Gaussian filter.\n    '''\n    # TODO: Implement the Gaussian filter application logic.\n",
        "answer": "'''\nThis function will take an image and the Gaussian kernel as inputs.\nIt will process the image by applying the Gaussian filter, smoothing the pixel values and effectively reducing noise.\n\nARGUMENTS:\nimage: np.ndarray - The input image on which to apply the Gaussian filter.\nkernel: np.ndarray - The Gaussian kernel to use for smoothing.\n\nRETURN: np.ndarray - The filtered image after applying the Gaussian filter.\n'''\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef apply_gaussian_filter(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n    # Ensure the kernel is normalized\n    kernel = kernel / np.sum(kernel)\n    \n    # Apply the Gaussian filter using convolution\n    filtered_image = convolve(image, kernel, mode='reflect')\n    \n    return filtered_image"
    },
    {
        "requirement": "def APPLY_MEDIAN_FILTER(image: np.ndarray) -> np.ndarray:\n    '''\n    This function will implement the 3x3 median filter algorithm on the grayscale image.\n    It will slide the 3x3 window across the image pixels, compute the median for each window, and create a new filtered image.\n    \n    ARGUMENTS:\n    - image: np.ndarray - The input grayscale image as a NumPy array.\n\n    RETURN:\n    - np.ndarray - The filtered image after applying the median filter.\n    '''\n    # TODO: Apply the median filter using scipy.ndimage.median_filter\n",
        "answer": "'''\nThis function will implement the 3x3 median filter algorithm on the grayscale image.\nIt will slide the 3x3 window across the image pixels, compute the median for each window, and create a new filtered image.\n\nARGUMENTS:\n- image: np.ndarray - The input grayscale image as a NumPy array.\n\nRETURN:\n- np.ndarray - The filtered image after applying the median filter.\n'''\nimport numpy as np\nfrom scipy.ndimage import median_filter\n\ndef APPLY_MEDIAN_FILTER(image: np.ndarray) -> np.ndarray:\n    # Apply the median filter using scipy.ndimage.median_filter\n    filtered_image = median_filter(image, size=3)\n    return filtered_image"
    },
    {
        "requirement": "def apply_median_filter(image: np.ndarray) -> np.ndarray:\n    '''\n    This function iterates over each pixel in the input image, extracts the 3x3 neighborhood for each \n    target pixel, calculates the median value, and constructs the output image.\n    \n    ARGUMENTS:\n    image: np.ndarray - The input image to which the median filter will be applied.\n\n    RETURN: np.ndarray - The filtered output image.\n    '''\n    # Initialize the output image with the same shape as the input\n    output_image = np.zeros_like(image)\n    rows, cols = image.shape\n    \n    # Iterate through each pixel in the image (avoiding borders)\n    for i in range(1, rows - 1):\n        for j in range(1, cols - 1):\n            # Extract the 3x3 neighborhood\n            neighborhood = image[i - 1:i + 2, j - 1:j + 2].flatten()\n            # Calculate the median of the neighborhood\n            output_image[i, j] = get_median(neighborhood)\n    \n    return output_image\n\n",
        "answer": "'''\nThis function iterates over each pixel in the input image, extracts the 3x3 neighborhood for each \ntarget pixel, calculates the median value, and constructs the output image.\n\nARGUMENTS:\nimage: np.ndarray - The input image to which the median filter will be applied.\n\nRETURN: np.ndarray - The filtered output image.\n'''\nimport numpy as np\n\ndef get_median(neighborhood: np.ndarray) -> int:\n    '''Helper function to calculate the median of a 1D numpy array.'''\n    return int(np.median(neighborhood))\n\ndef apply_median_filter(image: np.ndarray) -> np.ndarray:\n    # Initialize the output image with the same shape as the input\n    output_image = np.zeros_like(image)\n    rows, cols = image.shape\n    \n    # Iterate through each pixel in the image (avoiding borders)\n    for i in range(1, rows - 1):\n        for j in range(1, cols - 1):\n            # Extract the 3x3 neighborhood\n            neighborhood = image[i - 1:i + 2, j - 1:j + 2].flatten()\n            # Calculate the median of the neighborhood\n            output_image[i, j] = get_median(neighborhood)\n    \n    return output_image"
    },
    {
        "requirement": "def get_median(values: list) -> int:\n    '''\n    This function takes a list of pixel values (from the 3x3 region) and returns the median value.\n    \n    ARGUMENTS:\n    values: list - A list of pixel intensity values from the 3x3 neighborhood.\n\n    RETURN: int - The median value of the input list.\n    '''\n    return int(np.median(values))  # Use NumPy's median function for efficient calculation\n\n",
        "answer": "'''\nThis function takes a list of pixel values (from the 3x3 region) and returns the median value.\n\nARGUMENTS:\nvalues: list - A list of pixel intensity values from the 3x3 neighborhood.\n\nRETURN: int - The median value of the input list.\n'''\nimport numpy as np\n\ndef get_median(values: list) -> int:\n    return int(np.median(values))  # Use NumPy's median function for efficient calculation"
    },
    {
        "requirement": "def apply_smoothing_filter(image: np.ndarray) -> np.ndarray:\n    '''\n    Apply the 3x3 smoothing filter to the image, calculating the average value for \n    each pixel based on its surrounding pixels.\n    \n    ARGUMENTS:\n    image: np.ndarray - The input image in a numpy array format.\n    \n    RETURN: np.ndarray - The image after applying the smoothing filter.\n    '''\n    # Create an empty array to hold the filtered image\n    filtered_image = np.zeros_like(image)\n    \n    # Get dimensions of the image\n    rows, cols = image.shape[0], image.shape[1]\n    \n    # Apply the 3x3 smoothing filter\n    for i in range(1, rows - 1):\n        for j in range(1, cols - 1):\n            # Take the 3x3 window around the pixel (i, j)\n            window = image[i-1:i+2, j-1:j+2]\n            # Calculate the average of the pixel values in the window\n            average_value = np.mean(window)\n            filtered_image[i, j] = average_value\n            \n    # Return the filtered image\n    return filtered_image\n",
        "answer": "'''\nApply the 3x3 smoothing filter to the image, calculating the average value for \neach pixel based on its surrounding pixels.\n\nARGUMENTS:\nimage: np.ndarray - The input image in a numpy array format.\n\nRETURN: np.ndarray - The image after applying the smoothing filter.\n'''\ndef apply_smoothing_filter(image: np.ndarray) -> np.ndarray:\n    # Create an empty array to hold the filtered image\n    filtered_image = np.zeros_like(image)\n    \n    # Get dimensions of the image\n    rows, cols = image.shape[0], image.shape[1]\n    \n    # Apply the 3x3 smoothing filter\n    for i in range(1, rows - 1):\n        for j in range(1, cols - 1):\n            # Take the 3x3 window around the pixel (i, j)\n            window = image[i-1:i+2, j-1:j+2]\n            # Calculate the average of the pixel values in the window\n            average_value = np.mean(window)\n            filtered_image[i, j] = average_value\n            \n    return filtered_image"
    },
    {
        "requirement": "def apply_motion_filter(image: np.array) -> any:\n    '''\n    This function will implement the 3x3 motion filter algorithm, \n    calculating the average values in the diagonal direction and applying \n    the filter to the input image to generate the filtered output image.\n    ARGUMENTS: \n        image: any - The input image as a NumPy array on which the filter will be applied.\n    RETURN: \n        any - The filtered output image as a NumPy array.\n    '''\n    # Initialize the output image\n    filtered_image = image.copy()\n    \n    # Get the dimensions of the image\n    height, width = image.shape[:2]\n    \n    # Define the 3x3 motion filter kernel\n    kernel = [[0, 1, 0], \n              [0, 1, 0], \n              [0, 1, 0]]  # A simplified version that only considers the diagonal average\n    \n    # Apply the motion filter\n    for i in range(1, height - 1):\n        for j in range(1, width - 1):\n            # Calculate the average value along the diagonal (for simplicity)\n            diagonal_sum = (image[i - 1, j - 1] + image[i, j] + image[i + 1, j + 1]) / 3\n            filtered_image[i, j] = diagonal_sum\n    \n    return filtered_image\n",
        "answer": "'''\nThis function will implement the 3x3 motion filter algorithm, \ncalculating the average values in the diagonal direction and applying \nthe filter to the input image to generate the filtered output image.\nARGUMENTS: \n    image: any - The input image as a NumPy array on which the filter will be applied.\nRETURN: \n    any - The filtered output image as a NumPy array.\n'''\nimport numpy as np\n\ndef apply_motion_filter(image: np.ndarray) -> np.ndarray:\n    # Initialize the output image\n    filtered_image = image.copy()\n    \n    # Get the dimensions of the image\n    height, width = image.shape[:2]\n    \n    # Apply the motion filter\n    for i in range(1, height - 1):\n        for j in range(1, width - 1):\n            # Calculate the average value along the diagonal\n            diagonal_sum = (image[i - 1, j - 1] + image[i, j] + image[i + 1, j + 1]) / 3\n            filtered_image[i, j] = diagonal_sum\n    \n    return filtered_image"
    },
    {
        "requirement": "def apply_max_min_filter(image:np.ndarray) -> np.ndarray:\n    '''\n    Traverses the input image and applies the 3x3 Max-Min filter to compute\n    the difference between the maximum and minimum pixel values within each \n    3x3 window, returning the filtered output image.\n    ARGUMENTS: \n        image: np.ndarray - the input grayscale image as a numpy array.\n    RETURN: \n        np.ndarray - the filtered output image as a numpy array.\n    '''\n    # Get the dimensions of the input image\n    height, width = image.shape\n    # Create an output image initialized to zeros\n    output_image = np.zeros((height, width), dtype=np.uint8)\n\n    # Traverse the image with a 3x3 filter\n    for i in range(1, height - 1):\n        for j in range(1, width - 1):\n            # Extract the 3x3 window\n            window = image[i-1:i+2, j-1:j+2]\n            # Compute the max and min values in the window\n            max_val = np.max(window)\n            min_val = np.min(window)\n            # Calculate the difference and assign to the output image\n            output_image[i, j] = max_val - min_val\n\n    return output_image\n\n",
        "answer": "'''\nTraverses the input image and applies the 3x3 Max-Min filter to compute\nthe difference between the maximum and minimum pixel values within each \n3x3 window, returning the filtered output image.\nARGUMENTS: \n    image: np.ndarray - the input grayscale image as a numpy array.\nRETURN: \n    np.ndarray - the filtered output image as a numpy array.\n'''\ndef apply_max_min_filter(image: np.ndarray) -> np.ndarray:\n    # Get the dimensions of the input image\n    height, width = image.shape\n    # Create an output image initialized to zeros\n    output_image = np.zeros((height, width), dtype=np.uint8)\n\n    # Traverse the image with a 3x3 filter\n    for i in range(1, height - 1):\n        for j in range(1, width - 1):\n            # Extract the 3x3 window\n            window = image[i-1:i+2, j-1:j+2]\n            # Compute the max and min values in the window\n            max_val = np.max(window)\n            min_val = np.min(window)\n            # Calculate the difference and assign to the output image\n            output_image[i, j] = max_val - min_val\n\n    return output_image"
    },
    {
        "requirement": "def max_min_filter(image_path:str, output_path:str) -> None:\n    '''\n    Orchestrates the overall process by calling the relevant functions to \n    load the image, apply the Max-Min filter, and save the output image.\n    ARGUMENTS: \n        image_path: str - the path to the input image file.\n        output_path: str - the path to save the filtered output image.\n    RETURN: \n        None\n    '''\n    # Load the image\n    image = load_image(image_path)\n    # Apply the Max-Min filter\n    filtered_image = apply_max_min_filter(image)\n    # Save the filtered image\n    save_image(filtered_image, output_path)\n```\n\n### External Libraries Used:\n- **numpy**: for handling arrays and performing vectorized operations efficiently.\n- **cv2 (OpenCV)**: for loading and saving images in different formats.",
        "answer": "'''\nApplies a Max-Min filter to an image, orchestrating the loading, filtering, and saving processes.\nARGUMENTS: \n    image_path: str - the path to the input image file.\n    output_path: str - the path to save the filtered output image.\nRETURN: \n    None\n'''\nimport numpy as np\nimport cv2\n\ndef load_image(image_path: str) -> np.ndarray:\n    ''' Loads an image from the specified path. '''\n    return cv2.imread(image_path)\n\ndef save_image(image: np.ndarray, output_path: str) -> None:\n    ''' Saves the image to the specified output path. '''\n    cv2.imwrite(output_path, image)\n\ndef apply_max_min_filter(image: np.ndarray, filter_size: int = 3) -> np.ndarray:\n    ''' \n    Applies a Max-Min filter to the given image using a specified filter size. \n    The filter replaces each pixel with the difference between the max and min pixel \n    values in the local neighborhood defined by the filter size.\n    '''\n    padded_image = np.pad(image, ((filter_size // 2, filter_size // 2), (filter_size // 2, filter_size // 2), (0, 0)), mode='edge')\n    filtered_image = np.zeros_like(image)\n\n    for i in range(image.shape[0]):\n        for j in range(image.shape[1]):\n            region = padded_image[i:i + filter_size, j:j + filter_size]\n            max_value = np.max(region)\n            min_value = np.min(region)\n            filtered_image[i, j] = max_value - min_value\n\n    return filtered_image\n\ndef max_min_filter(image_path: str, output_path: str) -> None:\n    '''\n    Orchestrates the overall process by calling the relevant functions to \n    load the image, apply the Max-Min filter, and save the output image.\n    ARGUMENTS: \n        image_path: str - the path to the input image file.\n        output_path: str - the path to save the filtered output image.\n    RETURN: \n        None\n    '''\n    # Load the image\n    image = load_image(image_path)\n    # Apply the Max-Min filter\n    filtered_image = apply_max_min_filter(image)\n    # Save the filtered image\n    save_image(filtered_image, output_path)"
    },
    {
        "requirement": "def APPLY_DIFFERENTIAL_FILTER(image_array: np.ndarray) -> np.ndarray:\n    '''\n    This function will take the image array as input, apply the 3x3 differential filter to detect edges, \n    and return the processed image array with the detected edges.\n    ARGUMENTS:\n    - image_array: np.ndarray - The input image represented as a NumPy array.\n    RETURN: np.ndarray - The processed image array with detected edges.\n    '''\n    # TODO: Implement the 3x3 differential filter logic\n    # Example filter for detecting vertical edges:\n    filter_kernel = np.array([[1, 0, -1],\n                               [1, 0, -1],\n                               [1, 0, -1]])\n    # Apply convolution operation here using the filter\n    # You may need to handle image borders (padding) during this operation\n    return processed_image\n",
        "answer": "'''\nThis function will take the image array as input, apply the 3x3 differential filter to detect edges, \nand return the processed image array with the detected edges.\nARGUMENTS:\n- image_array: np.ndarray - The input image represented as a NumPy array.\nRETURN: np.ndarray - The processed image array with detected edges.\n'''\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef APPLY_DIFFERENTIAL_FILTER(image_array: np.ndarray) -> np.ndarray:\n    # Define the 3x3 differential filter for detecting vertical edges\n    filter_kernel = np.array([[1, 0, -1],\n                               [1, 0, -1],\n                               [1, 0, -1]])\n    \n    # Apply convolution operation using the filter\n    # Padding the image to handle borders\n    padded_image = np.pad(image_array, pad_width=1, mode='edge')\n    \n    # Perform convolution\n    processed_image = convolve(padded_image, filter_kernel, mode='constant', cval=0.0)\n    \n    # Remove the padding\n    processed_image = processed_image[1:-1, 1:-1]\n    \n    # Normalize the output to the range [0, 255] and convert to uint8 if necessary\n    processed_image = np.clip(processed_image, 0, 255).astype(np.uint8)\n    \n    return processed_image"
    },
    {
        "requirement": "def apply_sobel_kernels(image: np.ndarray) -> (np.ndarray, np.ndarray):\n    '''\n    This function will apply the Sobel kernels (both vertical and horizontal) \n    to the loaded image to compute the gradients in both directions.\n    ARGUMENTS: \n    - image: np.ndarray - The input grayscale image.\n    RETURN: (np.ndarray, np.ndarray) - Two NumPy arrays representing the gradient images: \n        (gradient_x, gradient_y)\n    '''\n    # Define the Sobel kernels\n    sobel_kernel_x = np.array([[1, 0, -1],\n                                [2, 0, -2],\n                                [1, 0, -1]])\n    \n    sobel_kernel_y = np.array([[1, 2, 1],\n                                [0, 0, 0],\n                                [-1, -2, -1]])\n    \n    # Apply convolution using NumPy\n    gradient_x = convolve2d(image, sobel_kernel_x)  # Implement convolve2d separately\n    gradient_y = convolve2d(image, sobel_kernel_y)  # Implement convolve2d separately\n    \n    return gradient_x, gradient_y\n",
        "answer": "'''\nThis function will apply the Sobel kernels (both vertical and horizontal) \nto the loaded image to compute the gradients in both directions.\nARGUMENTS: \n- image: np.ndarray - The input grayscale image.\nRETURN: (np.ndarray, np.ndarray) - Two NumPy arrays representing the gradient images: \n    (gradient_x, gradient_y)\n'''\n\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef apply_sobel_kernels(image: np.ndarray) -> (np.ndarray, np.ndarray):\n    # Define the Sobel kernels\n    sobel_kernel_x = np.array([[1, 0, -1],\n                                [2, 0, -2],\n                                [1, 0, -1]])\n    \n    sobel_kernel_y = np.array([[1, 2, 1],\n                                [0, 0, 0],\n                                [-1, -2, -1]])\n    \n    # Apply convolution using NumPy\n    gradient_x = convolve2d(image, sobel_kernel_x, mode='same', boundary='symm')  # Ensure the image edges are handled\n    gradient_y = convolve2d(image, sobel_kernel_y, mode='same', boundary='symm')  # Ensure the image edges are handled\n    \n    return gradient_x, gradient_y"
    },
    {
        "requirement": "def calculate_magnitude_and_direction(gradient_x: np.ndarray, gradient_y: np.ndarray) -> (np.ndarray, np.ndarray):\n    '''\n    This function will calculate the gradient magnitude and direction \n    from the results of the Sobel kernel applications to highlight the edges in the image.\n    ARGUMENTS:\n    - gradient_x: np.ndarray - The gradient image in the x-direction.\n    - gradient_y: np.ndarray - The gradient image in the y-direction.\n    RETURN: (np.ndarray, np.ndarray) - Two NumPy arrays representing the gradient magnitude and direction:\n        (magnitude, direction)\n    '''\n    # Calculate magnitude and direction\n    magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n    direction = np.arctan2(gradient_y, gradient_x)  # Get direction in radians\n    \n    return magnitude, direction\n",
        "answer": "'''\nThis function will calculate the gradient magnitude and direction \nfrom the results of the Sobel kernel applications to highlight the edges in the image.\nARGUMENTS:\n- gradient_x: np.ndarray - The gradient image in the x-direction.\n- gradient_y: np.ndarray - The gradient image in the y-direction.\nRETURN: (np.ndarray, np.ndarray) - Two NumPy arrays representing the gradient magnitude and direction:\n    (magnitude, direction)\n'''\ndef calculate_magnitude_and_direction(gradient_x: np.ndarray, gradient_y: np.ndarray) -> (np.ndarray, np.ndarray):\n    # Calculate magnitude and direction\n    magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n    direction = np.arctan2(gradient_y, gradient_x)  # Get direction in radians\n    \n    return magnitude, direction"
    },
    {
        "requirement": "def apply_prewitt_filter(image: np.ndarray) -> np.ndarray:\n    '''\n    Apply the 3x3 Prewitt filter on the loaded image,\n    calculating the gradients in the x and y directions \n    and combining them to produce the final edge-detected image.\n    \n    ARGUMENTS:\n    - image: np.ndarray - The input image as a NumPy array.\n    \n    RETURN:\n    - np.ndarray - The resulting edge-detected image after applying the Prewitt filter.\n    '''\n    # Prewitt kernels\n    Gx = np.array([[ -1, 0, 1],\n                   [ -1, 0, 1],\n                   [ -1, 0, 1]])\n    \n    Gy = np.array([[ 1, 1, 1],\n                   [ 0, 0, 0],\n                   [ -1, -1, -1]])\n    \n    # TODO: Implement convolution for x and y gradients\n    # TODO: Combine Gx and Gy to get the edge-detected image\n    # Note: Implement edge handling (padding) as necessary\n    return edge_detected_image\n\n",
        "answer": "'''\nApply the 3x3 Prewitt filter on the loaded image,\ncalculating the gradients in the x and y directions \nand combining them to produce the final edge-detected image.\n\nARGUMENTS:\n- image: np.ndarray - The input image as a NumPy array.\n\nRETURN:\n- np.ndarray - The resulting edge-detected image after applying the Prewitt filter.\n'''\nimport numpy as np\nfrom scipy.ndimage import convolution\n\ndef apply_prewitt_filter(image: np.ndarray) -> np.ndarray:\n    # Prewitt kernels\n    Gx = np.array([[ -1, 0, 1],\n                   [ -1, 0, 1],\n                   [ -1, 0, 1]])\n    \n    Gy = np.array([[ 1, 1, 1],\n                   [ 0, 0, 0],\n                   [ -1, -1, -1]])\n    \n    # Compute the gradients in the x and y directions\n    gradient_x = convolution(image, Gx, mode='reflect')\n    gradient_y = convolution(image, Gy, mode='reflect')\n    \n    # Combine the gradients to get the edge-detected image\n    edge_detected_image = np.sqrt(gradient_x**2 + gradient_y**2)\n    \n    # Normalize the result to the range [0, 255]\n    edge_detected_image = (edge_detected_image / np.max(edge_detected_image) * 255).astype(np.uint8)\n    \n    return edge_detected_image"
    },
    {
        "requirement": "def compute_laplacian(image:np.ndarray) -> np.ndarray:\n    '''\n    Applies the Laplacian operator to the image to compute the second derivative of luminance, highlighting edges.\n    ARGUMENTS: image (np.ndarray) - The grayscale image on which the Laplacian filter will be applied.\n    RETURN: np.ndarray - The image with edges highlighted through the Laplacian filter.\n    '''\n    # Apply the Laplacian operator\n    laplacian_image = cv2.Laplacian(image, cv2.CV_64F)\n    return laplacian_image\n",
        "answer": "'''\nApplies the Laplacian operator to the image to compute the second derivative of luminance, highlighting edges.\nARGUMENTS: image (np.ndarray) - The grayscale image on which the Laplacian filter will be applied.\nRETURN: np.ndarray - The image with edges highlighted through the Laplacian filter.\n'''\nimport numpy as np\nimport cv2\n\ndef compute_laplacian(image: np.ndarray) -> np.ndarray:\n    # Apply the Laplacian operator\n    laplacian_image = cv2.Laplacian(image, cv2.CV_64F)\n    return laplacian_image"
    },
    {
        "requirement": "def apply_emboss_filter(input_image: numpy.ndarray) -> numpy.ndarray:\n    '''\n    This function takes an input image and applies the emboss filter algorithm \n    to manipulate pixel data, utilizing convolution to achieve the desired \n    embossing effect. It will return the modified image.\n    \n    ARGUMENTS:\n    input_image : numpy.ndarray - The input image on which the emboss filter is to be applied.\n    \n    RETURN:\n    numpy.ndarray - The modified image after applying the emboss filter.\n    '''\n    # TODO: Implement the emboss filter algorithm using pixel manipulation and convolution\n    ",
        "answer": "'''\nThis function takes an input image and applies the emboss filter algorithm \nto manipulate pixel data, utilizing convolution to achieve the desired \nembossing effect. It will return the modified image.\n\nARGUMENTS:\ninput_image : numpy.ndarray - The input image on which the emboss filter is to be applied.\n\nRETURN:\nnumpy.ndarray - The modified image after applying the emboss filter.\n'''\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef apply_emboss_filter(input_image: np.ndarray) -> np.ndarray:\n    # Define the emboss kernel\n    emboss_kernel = np.array([[2,  0, 0],\n                               [0,  0, 0],\n                               [0, -1, -1]])\n    \n    # Apply convolution using the emboss kernel\n    embossed_image = convolve(input_image, emboss_kernel)\n    \n    # Clip the values to be in the valid range for an image\n    embossed_image = np.clip(embossed_image, 0, 255)\n\n    # Convert to an appropriate data type\n    return embossed_image.astype(np.uint8)"
    },
    {
        "requirement": "def convolve_kernel(image: numpy.ndarray, kernel: numpy.ndarray) -> numpy.ndarray:\n    '''\n    This function performs the convolution operation using a predefined emboss \n    kernel/filter, processing the pixel values to enhance edges and create the \n    embossing effect. It will be a helper function used within the \n    apply_emboss_filter function.\n    \n    ARGUMENTS:\n    image : numpy.ndarray - The input image to be processed by the convolution operation.\n    kernel : numpy.ndarray - The convolution kernel/filter used for the emboss effect.\n    \n    RETURN:\n    numpy.ndarray - The image after applying the convolution with the emboss kernel.\n    '''\n    # TODO: Implement the convolution operation using the provided kernel\n",
        "answer": "'''\nThis function performs the convolution operation using a predefined emboss \nkernel/filter, processing the pixel values to enhance edges and create the \nembossing effect. It will be a helper function used within the \napply_emboss_filter function.\n\nARGUMENTS:\nimage : numpy.ndarray - The input image to be processed by the convolution operation.\nkernel : numpy.ndarray - The convolution kernel/filter used for the emboss effect.\n\nRETURN:\nnumpy.ndarray - The image after applying the convolution with the emboss kernel.\n'''\nimport numpy as np\n\ndef convolve_kernel(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n    # Get the dimensions of the image and the kernel\n    image_height, image_width = image.shape\n    kernel_height, kernel_width = kernel.shape\n    \n    # Calculate the padding sizes\n    pad_height = kernel_height // 2\n    pad_width = kernel_width // 2\n\n    # Pad the image with zeros on all sides\n    padded_image = np.pad(image, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant', constant_values=0)\n\n    # Create an output array to store the results\n    output_image = np.zeros_like(image)\n\n    # Perform the convolution operation\n    for i in range(image_height):\n        for j in range(image_width):\n            # Apply the kernel to the corresponding region of the padded image\n            region = padded_image[i:i + kernel_height, j:j + kernel_width]\n            output_value = np.sum(region * kernel)\n            # Update output image after clamping the values to be in the valid range\n            output_image[i, j] = np.clip(output_value, 0, 255)  # Assuming image pixel values are in [0, 255]\n\n    return output_image"
    },
    {
        "requirement": "def resize_image(input_image: numpy.ndarray, target_size: tuple) -> numpy.ndarray:\n    '''\n    This function resizes the input image if necessary, ensuring that the output \n    image maintains the correct dimensions after the embossing effect is applied, \n    particularly for edge cases in convolution.\n    \n    ARGUMENTS:\n    input_image : numpy.ndarray - The input image to be resized.\n    target_size : tuple - The desired dimensions for the output image (width, height).\n    \n    RETURN:\n    numpy.ndarray - The resized image with target dimensions.\n    '''\n    # TODO: Implement the image resizing based on the target dimensions\n```\n\n### External Libraries to be Used:\n- **NumPy**: This library will be utilized for image array manipulation (data structure for the image).\n- **OpenCV** (optional): If advanced image processing functions such as resizing and convolution are required directly, OpenCV can be integrated for those functionalities. \n\nPlease ensure that the necessary libraries are imported at the beginning of the script when these functions are implemented.",
        "answer": "'''\nThis function resizes the input image if necessary, ensuring that the output \nimage maintains the correct dimensions after the embossing effect is applied, \nparticularly for edge cases in convolution.\n\nARGUMENTS:\ninput_image : numpy.ndarray - The input image to be resized.\ntarget_size : tuple - The desired dimensions for the output image (width, height).\n\nRETURN:\nnumpy.ndarray - The resized image with target dimensions.\n'''\n\nimport numpy as np\nimport cv2\n\ndef resize_image(input_image: np.ndarray, target_size: tuple) -> np.ndarray:\n    # Get the current dimensions of the input image\n    current_height, current_width = input_image.shape[:2]\n    \n    # Unpack target_size into width and height\n    target_width, target_height = target_size\n    \n    # Check if resizing is necessary\n    if (current_width, current_height) != target_size:\n        # Resize the image using OpenCV\n        resized_image = cv2.resize(input_image, (target_width, target_height), interpolation=cv2.INTER_AREA)\n    else:\n        # If the sizes match, no resizing is needed\n        resized_image = input_image\n    \n    return resized_image"
    },
    {
        "requirement": "def apply_emboss_filter(image_data: Image) -> Image:\n    '''\n    This function applies the Emboss filter to the provided image data and returns the processed image data.\n    ARGUMENTS: image_data: The image data on which the Emboss filter is to be applied (Image)\n    RETURN: Image object containing the processed image data with emboss effect applied\n    '''\n    # Apply the Emboss filter using PIL\n    embossed_image = image_data.filter(ImageFilter.EMBOSS)\n    return embossed_image\n",
        "answer": "'''\nThis function applies the Emboss filter to the provided image data and returns the processed image data.\nARGUMENTS: image_data: The image data on which the Emboss filter is to be applied (Image)\nRETURN: Image object containing the processed image data with emboss effect applied\n'''\ndef apply_emboss_filter(image_data: Image) -> Image:\n    # Apply the Emboss filter using PIL\n    embossed_image = image_data.filter(ImageFilter.EMBOSS)\n    return embossed_image"
    },
    {
        "requirement": "def apply_gaussian_filter(image: np.ndarray, sigma: float = 3) -> np.ndarray:\n    '''\n    This function will apply the Gaussian filter to the input image \n    to suppress noise before edge detection.\n    ARGUMENTS: \n    - image: np.ndarray - The input image to which the Gaussian filter will be applied.\n    - sigma: float - The standard deviation for the Gaussian kernel (default value is 3).\n    RETURN: \n    - np.ndarray - The image after applying the Gaussian filter.\n    '''\n    # TODO: Implement the Gaussian filter using OpenCV\n    gaussian_image = cv2.GaussianBlur(image, (0, 0), sigma)\n    return gaussian_image\n",
        "answer": "'''\nThis function will apply the Gaussian filter to the input image \nto suppress noise before edge detection.\nARGUMENTS: \n- image: np.ndarray - The input image to which the Gaussian filter will be applied.\n- sigma: float - The standard deviation for the Gaussian kernel (default value is 3).\nRETURN: \n- np.ndarray - The image after applying the Gaussian filter.\n'''\nimport numpy as np\nimport cv2\n\ndef apply_gaussian_filter(image: np.ndarray, sigma: float = 3) -> np.ndarray:\n    gaussian_image = cv2.GaussianBlur(image, (0, 0), sigma)\n    return gaussian_image"
    },
    {
        "requirement": "def apply_laplacian_filter(image: np.ndarray) -> np.ndarray:\n    '''\n    This function will apply the Laplacian filter to the output \n    of the Gaussian filter to detect edges in the image.\n    ARGUMENTS: \n    - image: np.ndarray - The input image to which the Laplacian filter will be applied.\n    RETURN: \n    - np.ndarray - The image after applying the Laplacian filter (edge-detected image).\n    '''\n    # TODO: Implement the Laplacian filter using OpenCV\n    laplacian_image = cv2.Laplacian(image, cv2.CV_64F)\n    return laplacian_image\n",
        "answer": "'''\nThis function will apply the Laplacian filter to the output \nof the Gaussian filter to detect edges in the image.\nARGUMENTS: \n- image: np.ndarray - The input image to which the Laplacian filter will be applied.\nRETURN: \n- np.ndarray - The image after applying the Laplacian filter (edge-detected image).\n'''\nimport numpy as np\nimport cv2\n\ndef apply_laplacian_filter(image: np.ndarray) -> np.ndarray:\n    laplacian_image = cv2.Laplacian(image, cv2.CV_64F)\n    return laplacian_image"
    },
    {
        "requirement": "def CONVERT_IMAGE(image: np.ndarray) -> np.ndarray:\n    '''\n    This function will convert the loaded image data into a suitable format (e.g., NumPy array) \n    for further processing, preparing it for the histogram display and any subsequent analyses.\n    \n    ARGUMENTS:\n    image: np.ndarray -- The loaded image to be converted.\n    \n    RETURN:\n    np.ndarray -- The converted image data in a suitable format for processing.\n    '''\n    if image is None:\n        raise ValueError(\"Input image is None, cannot convert.\")\n    # Image is already in NumPy array from LOAD_IMAGE, returning it directly\n    return image\n\n",
        "answer": "'''\nThis function will convert the loaded image data into a suitable format (e.g., NumPy array) \nfor further processing, preparing it for the histogram display and any subsequent analyses.\n\nARGUMENTS:\nimage: np.ndarray -- The loaded image to be converted.\n\nRETURN:\nnp.ndarray -- The converted image data in a suitable format for processing.\n'''\ndef CONVERT_IMAGE(image: np.ndarray) -> np.ndarray:\n    if image is None:\n        raise ValueError(\"Input image is None, cannot convert.\")\n    \n    # Check if the image is in the correct format for processing\n    if len(image.shape) == 2:  # Grayscale image\n        return image.astype(np.float32)  # Convert to float for processing\n    elif len(image.shape) == 3:  # Color image\n        return image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n    else:\n        raise ValueError(\"Unsupported image format.\")"
    },
    {
        "requirement": "def VALIDATE_IMAGE(image: np.ndarray) -> bool:\n    '''\n    This function will verify the integrity and compatibility of the loaded image, ensuring that \n    the image meets the necessary criteria for processing (e.g., checking if the image is not empty, \n    verifying dimensions).\n    \n    ARGUMENTS:\n    image: np.ndarray -- The image to be validated.\n    \n    RETURN:\n    bool -- Returns True if the image is valid, otherwise False.\n    '''\n    if image is None or image.size == 0:\n        return False\n    # Verify image dimensions (must be a 2D or 3D array)\n    if len(image.shape) not in [2, 3]:\n        return False\n    return True\n```\n\n### Notes:\n- The implementation uses OpenCV (`cv2`) to handle image loading, as it supports various formats effectively.\n- NumPy is used to manage image data in array format for further processing.\n- Error handling is incorporated to ensure robust function behavior.\n- Each function is thoroughly documented to clarify its purpose, arguments, and return values.",
        "answer": "'''\nThis function will verify the integrity and compatibility of the loaded image, ensuring that \nthe image meets the necessary criteria for processing (e.g., checking if the image is not empty, \nverifying dimensions).\n\nARGUMENTS:\nimage: np.ndarray -- The image to be validated.\n\nRETURN:\nbool -- Returns True if the image is valid, otherwise False.\n'''\ndef VALIDATE_IMAGE(image: np.ndarray) -> bool:\n    if image is None or image.size == 0:\n        return False\n    # Verify image dimensions (must be a 2D or 3D array)\n    if len(image.shape) not in [2, 3]:\n        return False\n    # Additional dimension checks can be implemented here, e.g., checking for specific channels\n    if len(image.shape) == 3 and image.shape[2] not in [1, 3, 4]:\n        return False  # For example, it must be grayscale, RGB, or RGBA\n    return True"
    },
    {
        "requirement": "def compute_pixel_frequency(image: np.ndarray) -> np.ndarray:\n    '''\n    This function takes an input image and calculates the frequency of each pixel value (0-255) in the image,\n    returning a histogram array that represents the count of each pixel value.\n    \n    ARGUMENTS:\n    image: np.ndarray - The input image as a NumPy array, which can be grayscale or RGB.\n    \n    RETURN: \n    np.ndarray - An array of size 256, where each index corresponds to a pixel value \n                 and the value at each index represents its frequency in the input image.\n    '''\n    # TODO: Implement the logic to convert the image to grayscale if it's RGB,\n    # and calculate the histogram by counting pixel frequencies from 0 to 255.\n    pass\n",
        "answer": "'''\nThis function takes an input image and calculates the frequency of each pixel value (0-255) in the image,\nreturning a histogram array that represents the count of each pixel value.\n\nARGUMENTS:\nimage: np.ndarray - The input image as a NumPy array, which can be grayscale or RGB.\n\nRETURN: \nnp.ndarray - An array of size 256, where each index corresponds to a pixel value \n             and the value at each index represents its frequency in the input image.\n'''\nimport numpy as np\n\ndef compute_pixel_frequency(image: np.ndarray) -> np.ndarray:\n    # Check if the image is RGB (3 channels)\n    if image.ndim == 3:\n        # Convert to grayscale using the luminosity method\n        image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n    \n    # Ensure the image is in uint8 format for pixel values 0-255\n    image = image.astype(np.uint8)\n\n    # Calculate the histogram of pixel values\n    histogram, _ = np.histogram(image, bins=np.arange(256), density=False)\n    \n    return histogram"
    },
    {
        "requirement": "def visualize_histogram(histogram: np.ndarray) -> None:\n    '''\n    This function takes the histogram array generated by the compute_pixel_frequency function\n    and uses matplotlib's hist() function to display the histogram of the input image.\n    It sets appropriate labels and titles for clear visualization.\n    \n    ARGUMENTS:\n    histogram: np.ndarray - The histogram data representing counts of pixel values (0-255).\n    \n    RETURN: \n    None\n    '''\n    # TODO: Use matplotlib's hist() function to create a histogram plot,\n    # set x-label, y-label, title, and show the plot.\n    pass\n```\n\n### External Libraries Used:\n- **NumPy**: For handling the input image as an array and performing numerical operations.\n- **Matplotlib**: For plotting the histogram visualization.\n\nPlease proceed to delegate these functions to the Development Groups for implementation.",
        "answer": "'''\nThis function takes the histogram array generated by the compute_pixel_frequency function\nand uses matplotlib's hist() function to display the histogram of the input image.\nIt sets appropriate labels and titles for clear visualization.\n\nARGUMENTS:\nhistogram: np.ndarray - The histogram data representing counts of pixel values (0-255).\n\nRETURN: \nNone\n'''\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef visualize_histogram(histogram: np.ndarray) -> None:\n    plt.figure(figsize=(10, 6))\n    plt.bar(range(256), histogram, color='blue', alpha=0.7)\n    plt.title('Histogram of Pixel Intensity Values')\n    plt.xlabel('Pixel Intensity (0-255)')\n    plt.ylabel('Frequency')\n    plt.xlim([0, 255])\n    plt.grid(axis='y')\n    plt.show()"
    },
    {
        "requirement": "def normalize_histogram(image: np.ndarray) -> np.ndarray:\n    '''\n    Apply the gray-scale transformation equation to normalize and flatten the histogram of the image,\n    converting the pixel values to the specified range of [0, 255].\n    \n    ARGUMENTS:\n    image: np.ndarray - The input image in the form of a NumPy array.\n\n    RETURN:\n    np.ndarray - The normalized image in the form of a NumPy array.\n    '''\n    # TODO: Implement histogram normalization\n    c = np.min(image)  # Minimum pixel value in original image\n    d = np.max(image)  # Maximum pixel value in original image\n    a = 0              # Desired minimum pixel value\n    b = 255            # Desired maximum pixel value\n\n    normalized_image = (image - c) * (b - a) / (d - c) + a\n    normalized_image = np.clip(normalized_image, a, b).astype(np.uint8)  # Clip to [0, 255] and convert to uint8\n    return normalized_image\n",
        "answer": "'''\nApply the gray-scale transformation equation to normalize and flatten the histogram of the image,\nconverting the pixel values to the specified range of [0, 255].\n\nARGUMENTS:\nimage: np.ndarray - The input image in the form of a NumPy array.\n\nRETURN:\nnp.ndarray - The normalized image in the form of a NumPy array.\n'''\ndef normalize_histogram(image: np.ndarray) -> np.ndarray:\n    c = np.min(image)  # Minimum pixel value in original image\n    d = np.max(image)  # Maximum pixel value in original image\n    a = 0              # Desired minimum pixel value\n    b = 255            # Desired maximum pixel value\n\n    normalized_image = (image - c) * (b - a) / (d - c) + a\n    normalized_image = np.clip(normalized_image, a, b).astype(np.uint8)  # Clip to [0, 255] and convert to uint8\n    return normalized_image"
    },
    {
        "requirement": "def FLATTEN_HISTOGRAM(histogram: dict) -> dict:\n    '''\n    This function will implement the histogram flattening algorithm, \n    adjusting the histogram values to achieve a flat profile based on the calculated histogram.\n    ARGUMENTS: \n        histogram: dict - The input histogram with pixel intensity counts.\n    RETURN: \n        dict - A modified histogram with flattened values.\n    '''\n    # TODO: Implement histogram flattening logic.\n    flatten_histogram = {i: histogram[i] for i in histogram}  # Placeholder for flattening logic\n    total_pixels = sum(flatten_histogram.values())\n    for intensity in flatten_histogram.keys():\n        flatten_histogram[intensity] = total_pixels // len(flatten_histogram)  # Simplified approach\n    return flatten_histogram\n\n",
        "answer": "'''\nThis function will implement the histogram flattening algorithm, \nadjusting the histogram values to achieve a flat profile based on the calculated histogram.\nARGUMENTS: \n    histogram: dict - The input histogram with pixel intensity counts.\nRETURN: \n    dict - A modified histogram with flattened values.\n'''\ndef FLATTEN_HISTOGRAM(histogram: dict) -> dict:\n    flatten_histogram = {i: histogram[i] for i in histogram}  # Initialize with original values\n    total_pixels = sum(flatten_histogram.values())\n    num_intensities = len(flatten_histogram)\n\n    # Calculate the target value for each intensity level.\n    target_value = total_pixels // num_intensities\n\n    # Adjust the histogram values to achieve the flattened profile.\n    for intensity in flatten_histogram.keys():\n        flatten_histogram[intensity] = target_value\n        \n    # If rounding down leads to fewer total pixels, adjust the last intensity value.\n    if total_pixels % num_intensities != 0:\n        flatten_histogram[max(flatten_histogram.keys())] += total_pixels % num_intensities\n\n    return flatten_histogram"
    },
    {
        "requirement": "def APPLY_FLATTENING(image: 'Image', new_histogram: dict) -> 'Image':\n    '''\n    This function will apply the modified histogram values to the original image, \n    resulting in the new balanced image.\n    ARGUMENTS: \n        image: Image - The original input image.\n        new_histogram: dict - The flattened histogram values to be applied to the image.\n    RETURN: \n        Image - The new balanced image after applying histogram flattening.\n    '''\n    # TODO: Use NumPy to map the pixel values according to the new histogram.\n    import numpy as np\n    img_array = np.array(image)\n    # Placeholder for applying the flattening - actual mapping should be done based on new_histogram\n    flatten_palette = np.array(list(new_histogram.values()))\n    balanced_image = flatten_palette[img_array]  # A simple transformation example\n    return Image.fromarray(np.uint8(balanced_image))\n\n",
        "answer": "'''\nThis function will apply the modified histogram values to the original image, \nresulting in the new balanced image.\nARGUMENTS: \n    image: Image - The original input image.\n    new_histogram: dict - The flattened histogram values to be applied to the image.\nRETURN: \n    Image - The new balanced image after applying histogram flattening.\n'''\ndef APPLY_FLATTENING(image: 'Image', new_histogram: dict) -> 'Image':\n    import numpy as np\n    img_array = np.array(image)\n    \n    # Create a mapping from the original pixel values to the new pixel values based on the new histogram\n    # Assuming new_histogram maps original pixel values to new pixel values\n    max_val = 255  # assuming 8-bit images\n    pixel_mapping = np.zeros(max_val + 1, dtype=np.uint8)\n    \n    # Generate the mapping\n    cum_sum = 0\n    for i in range(len(new_histogram)):\n        cum_sum += new_histogram.get(i, 0)\n        pixel_mapping[i] = np.clip(cum_sum, 0, max_val)\n        \n    # Map the original image array to the new pixel values\n    balanced_image = pixel_mapping[img_array]\n    return Image.fromarray(np.uint8(balanced_image))"
    },
    {
        "requirement": "def apply_gamma_correction(image: Image, c: float = 1.0, g: float = 2.2) -> Image:\n    '''\n    This function will implement the gamma correction algorithm using the formula with parameters c = 1 and g = 2.2 to adjust the RGB pixel values of the loaded image.\n    ARGUMENTS:\n        image: Image - The loaded image object to which gamma correction will be applied.\n        c: float - The constant value (default is 1.0).\n        g: float - The gamma value (default is 2.2).\n    RETURN:\n        Image - The gamma-corrected image object.\n    '''\n    # TODO: Implement the gamma correction algorithm\n    img_array = np.array(image) / 255.0  # Normalize pixel values\n    corrected_array = c * (img_array ** (1 / g))  # Apply gamma correction\n    corrected_image = Image.fromarray((corrected_array * 255).astype(np.uint8))  # Convert back to image\n    return corrected_image\n",
        "answer": "'''\nThis function will implement the gamma correction algorithm using the formula with parameters c = 1 and g = 2.2 to adjust the RGB pixel values of the loaded image.\nARGUMENTS:\n    image: Image - The loaded image object to which gamma correction will be applied.\n    c: float - The constant value (default is 1.0).\n    g: float - The gamma value (default is 2.2).\nRETURN:\n    Image - The gamma-corrected image object.\n'''\ndef apply_gamma_correction(image: Image, c: float = 1.0, g: float = 2.2) -> Image:\n    import numpy as np\n    from PIL import Image\n    \n    img_array = np.array(image) / 255.0  # Normalize pixel values\n    corrected_array = c * (img_array ** (1 / g))  # Apply gamma correction\n    corrected_image = Image.fromarray((corrected_array * 255).astype(np.uint8))  # Convert back to image\n    return corrected_image"
    },
    {
        "requirement": "def ENLARGE_IMAGE(image_data: np.ndarray) -> np.ndarray:\n    '''\n    This function will implement the nearest neighbor interpolation algorithm to enlarge\n    the image by 1.5 times, using the pixel data obtained from the READ_IMAGE function.\n    \n    ARGUMENTS:\n    - image_data: np.ndarray - A matrix of pixel values representing the original image.\n    \n    RETURN:\n    - np.ndarray - A matrix of pixel values representing the enlarged image.\n    '''\n    # TODO: Implement nearest neighbor interpolation to enlarge the image by 1.5 times.\n    original_height, original_width = image_data.shape[0], image_data.shape[1]\n    enlarged_height, enlarged_width = int(original_height * 1.5), int(original_width * 1.5)\n    \n    enlarged_image = np.zeros((enlarged_height, enlarged_width, image_data.shape[2]), dtype=image_data.dtype)\n    \n    for y in range(enlarged_height):\n        for x in range(enlarged_width):\n            orig_y = int(y / 1.5)\n            orig_x = int(x / 1.5)\n            enlarged_image[y, x] = image_data[orig_y, orig_x]\n\n    return enlarged_image\n",
        "answer": "'''\nThis function will implement the nearest neighbor interpolation algorithm to enlarge\nthe image by 1.5 times, using the pixel data obtained from the READ_IMAGE function.\n\nARGUMENTS:\n- image_data: np.ndarray - A matrix of pixel values representing the original image.\n\nRETURN:\n- np.ndarray - A matrix of pixel values representing the enlarged image.\n'''\nimport numpy as np\n\ndef ENLARGE_IMAGE(image_data: np.ndarray) -> np.ndarray:\n    original_height, original_width = image_data.shape[0], image_data.shape[1]\n    enlarged_height, enlarged_width = int(original_height * 1.5), int(original_width * 1.5)\n    \n    # Create an empty array with the new dimensions\n    enlarged_image = np.zeros((enlarged_height, enlarged_width, image_data.shape[2]), dtype=image_data.dtype)\n    \n    for y in range(enlarged_height):\n        for x in range(enlarged_width):\n            # Calculate the corresponding pixel in the original image\n            orig_y = int(y / 1.5)\n            orig_x = int(x / 1.5)\n            # Ensure we don't go out of bounds\n            orig_y = min(orig_y, original_height - 1)\n            orig_x = min(orig_x, original_width - 1)\n            enlarged_image[y, x] = image_data[orig_y, orig_x]\n\n    return enlarged_image"
    },
    {
        "requirement": "def apply_bilinear_interpolation(original_image: np.ndarray) -> np.ndarray:\n    '''\n    This function will perform the bi-linear interpolation calculations to enlarge the original image by 1.5 times,\n    taking into account the four surrounding pixels for each pixel in the enlarged image.\n    ARGUMENTS: \n        original_image: np.ndarray - The original image data as a NumPy array.\n    RETURN: \n        np.ndarray - The enlarged image data after applying bi-linear interpolation.\n    '''\n    # TODO: Implement bi-linear interpolation algorithm to enlarge the original_image by 1.5 times\n    original_height, original_width = original_image.shape[0:2]\n    new_height = int(original_height * 1.5)\n    new_width = int(original_width * 1.5)\n    \n    enlarged_image = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n    \n    for i in range(new_height):\n        for j in range(new_width):\n            # TODO: Calculate the corresponding pixel in the original image\n            # Use bi-linear interpolation method to compute the pixel value\n            pass  # This is where the logic for interpolation will go\n            \n    return enlarged_image\n\n",
        "answer": "'''\nThis function will perform the bi-linear interpolation calculations to enlarge the original image by 1.5 times,\ntaking into account the four surrounding pixels for each pixel in the enlarged image.\nARGUMENTS: \n    original_image: np.ndarray - The original image data as a NumPy array.\nRETURN: \n    np.ndarray - The enlarged image data after applying bi-linear interpolation.\n'''\nimport numpy as np\n\ndef apply_bilinear_interpolation(original_image: np.ndarray) -> np.ndarray:\n    original_height, original_width = original_image.shape[0:2]\n    new_height = int(original_height * 1.5)\n    new_width = int(original_width * 1.5)\n    \n    enlarged_image = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n    \n    for i in range(new_height):\n        for j in range(new_width):\n            # Compute the coordinates in the original image\n            x = i / 1.5\n            y = j / 1.5\n            \n            # Calculate surrounding pixel coordinates\n            x0 = int(np.floor(x))\n            x1 = min(x0 + 1, original_height - 1)\n            y0 = int(np.floor(y))\n            y1 = min(y0 + 1, original_width - 1)\n            \n            # Calculate the fractional part\n            dx = x - x0\n            dy = y - y0\n            \n            # Bilinear interpolation formula\n            top = (1 - dx) * original_image[x0, y0] + dx * original_image[x1, y0]\n            bottom = (1 - dx) * original_image[x0, y1] + dx * original_image[x1, y1]\n            enlarged_image[i, j] = (1 - dy) * top + dy * bottom\n            \n    return enlarged_image"
    },
    {
        "requirement": "def bicubic_interpolation(input_image: np.ndarray, enlargement_factor: float = 1.5) -> np.ndarray:\n    '''\n    This function will implement the bi-cubic interpolation algorithm, taking the input image and the enlargement factor (1.5) \n    to calculate and generate the pixel values of the enlarged image.\n    \n    ARGUMENTS:\n    input_image: np.ndarray - The input image loaded as a NumPy array.\n    enlargement_factor: float - The factor by which to enlarge the image (default is 1.5).\n    \n    RETURN: np.ndarray - The enlarged image as a NumPy array.\n    '''\n    # TODO: Implement the bi-cubic interpolation algorithm\n    # Calculate new dimensions\n    height, width = input_image.shape[:2]\n    new_height = int(height * enlargement_factor)\n    new_width = int(width * enlargement_factor)\n    \n    # Create an output array\n    output_image = np.zeros((new_height, new_width, input_image.shape[2]), dtype=input_image.dtype)\n    \n    # TODO: Fill the output_image using bi-cubic interpolation based on input_image\n    return output_image\n\n",
        "answer": "'''\nThis function will implement the bi-cubic interpolation algorithm, taking the input image and the enlargement factor (1.5) \nto calculate and generate the pixel values of the enlarged image.\n\nARGUMENTS:\ninput_image: np.ndarray - The input image loaded as a NumPy array.\nenlargement_factor: float - The factor by which to enlarge the image (default is 1.5).\n\nRETURN: np.ndarray - The enlarged image as a NumPy array.\n'''\nimport numpy as np\n\ndef bicubic_interpolation(input_image: np.ndarray, enlargement_factor: float = 1.5) -> np.ndarray:\n    # Calculate new dimensions\n    height, width = input_image.shape[:2]\n    new_height = int(height * enlargement_factor)\n    new_width = int(width * enlargement_factor)\n    \n    # Create an output array\n    output_image = np.zeros((new_height, new_width, input_image.shape[2]), dtype=input_image.dtype)\n    \n    # Define the cubic interpolation kernel\n    def cubic(x):\n        if abs(x) <= 1:\n            return (1.5 * abs(x)**3 - 2.5 * abs(x)**2 + 1)\n        elif abs(x) < 2:\n            return (-0.5 * abs(x)**3 + 2.5 * abs(x)**2 - 4 * abs(x) + 2)\n        else:\n            return 0\n\n    # Calculate the output pixel values\n    for i in range(new_height):\n        for j in range(new_width):\n            # Find the corresponding pixel in the input image\n            x = (i / enlargement_factor)\n            y = (j / enlargement_factor)\n            \n            # Get the integer part and the fractional part\n            x_int = int(np.floor(x))\n            y_int = int(np.floor(y))\n            x_frac = x - x_int\n            y_frac = y - y_int\n            \n            # Initialize the pixel value\n            pixel_value = np.zeros(input_image.shape[2], dtype=input_image.dtype)\n            total_weight = 0\n            \n            # Loop over the cubic neighborhood\n            for m in range(-1, 3):\n                for n in range(-1, 3):\n                    # Calculate the neighboring pixel coordinates\n                    x_neigh = x_int + m\n                    y_neigh = y_int + n\n                    \n                    # Check if the neighbor is within the bounds of the input image\n                    if 0 <= x_neigh < height and 0 <= y_neigh < width:\n                        # Calculate weights using the cubic kernel\n                        weight = cubic(m - x_frac) * cubic(n - y_frac)\n                        pixel_value += weight * input_image[x_neigh, y_neigh]\n                        total_weight += weight\n            \n            if total_weight > 0:\n                pixel_value /= total_weight\n            \n            # Assign the pixel value to the output image\n            output_image[i, j] = pixel_value\n\n    return output_image"
    },
    {
        "requirement": "def APPLY_AFFINE_TRANSFORMATION(image:np.ndarray):\n    '''\n    Apply the affine transformation to translate the image by +30 in the x direction and -30 in the y direction.\n    ARGUMENTS: \n        image: The image to be transformed, provided as a NumPy array.\n    RETURN: \n        transformed_image: The transformed image as a NumPy array.\n    '''\n    # TODO: Implement function to apply the affine transformation\n    rows, cols = image.shape[:2]\n    translation_matrix = np.float32([[1, 0, 30], [0, 1, -30]])  # Matrix for translation\n    transformed_image = cv2.warpAffine(image, translation_matrix, (cols, rows))\n    return transformed_image\n```\n\n### Function 3: SAVE_IMAGE\n\n```python\nimport cv2  # External library for image processing\n",
        "answer": "'''\nThis function saves a given image to a specified file path.\nARGUMENTS: \n    image: The image to be saved, provided as a NumPy array.\n    file_path: The path where the image should be saved, including the file name and extension.\n'''\nimport cv2\nimport numpy as np\ndef SAVE_IMAGE(image: np.ndarray, file_path: str):\n    cv2.imwrite(file_path, image)"
    },
    {
        "requirement": "def apply_affine_transformation(image: Image) -> Image:\n    '''\n    This function will apply the affine transformation to resize the image \n    by 1.3 times in the x direction and 0.8 times in the y direction.\n    ARGUMENTS: \n    - image: Image - The input image object to be resized.\n    RETURN: Image - The resized image object.\n    '''\n    from PIL import Image\n    import numpy as np\n    \n    # Define the scaling factors\n    scale_x = 1.3\n    scale_y = 0.8\n    \n    # Define the affine transformation matrix\n    transformation_matrix = [\n        scale_x, 0, 0,\n        0, scale_y, 0\n    ]\n    \n    # Apply the affine transformation using the transform method\n    resized_image = image.transform(\n        (int(image.width * scale_x), int(image.height * scale_y)),\n        Image.AFFINE,\n        transformation_matrix,\n        resample=Image.BICUBIC\n    )\n    \n    return resized_image\n```\n\n### Function: save_image\n```python",
        "answer": "'''\nThis function will apply the affine transformation to resize the image \nby 1.3 times in the x direction and 0.8 times in the y direction.\nARGUMENTS: \n- image: Image - The input image object to be resized.\nRETURN: Image - The resized image object.\n'''\ndef apply_affine_transformation(image: Image) -> Image:\n    from PIL import Image\n    import numpy as np\n    \n    # Define the scaling factors\n    scale_x = 1.3\n    scale_y = 0.8\n    \n    # Define the affine transformation matrix\n    transformation_matrix = [\n        scale_x, 0, 0,\n        0, scale_y, 0\n    ]\n    \n    # Apply the affine transformation using the transform method\n    resized_image = image.transform(\n        (int(image.width * scale_x), int(image.height * scale_y)),\n        Image.AFFINE,\n        transformation_matrix,\n        resample=Image.BICUBIC\n    )\n    \n    return resized_image"
    },
    {
        "requirement": "def rotate_image(image: Image) -> (Image, tuple):\n    '''\n    This function will perform the affine transformation to rotate the image 30 degrees counterclockwise \n    and return the rotated image along with the new dimensions.\n    \n    ARGUMENTS:\n    image: Image - The input image to be rotated.\n    \n    RETURN:\n    (Image, tuple) - The rotated image and its new dimensions as a tuple (width, height).\n    '''\n    # Calculate the rotation matrix for 30 degrees counterclockwise\n    angle = 30\n    rotated_img = image.rotate(angle, expand=True)  # Expand to ensure the entire image is visible\n    new_dimensions = rotated_img.size\n    return rotated_img, new_dimensions\n\n",
        "answer": "'''\nThis function will perform the affine transformation to rotate the image 30 degrees counterclockwise \nand return the rotated image along with the new dimensions.\n\nARGUMENTS:\nimage: Image - The input image to be rotated.\n\nRETURN:\n(Image, tuple) - The rotated image and its new dimensions as a tuple (width, height).\n'''\ndef rotate_image(image: Image) -> (Image, tuple):\n    # Calculate the rotation matrix for 30 degrees counterclockwise\n    angle = 30\n    rotated_img = image.rotate(angle, expand=True)  # Expand to ensure the entire image is visible\n    new_dimensions = rotated_img.size\n    return rotated_img, new_dimensions"
    },
    {
        "requirement": "def translate_image(image: Image, new_size: tuple) -> Image:\n    '''\n    This function will calculate the necessary translation to ensure the entire rotated image is visible,\n    adjusting its position accordingly.\n    \n    ARGUMENTS:\n    image: Image - The rotated image to be translated.\n    new_size: tuple - The new dimensions (width, height) of the rotated image.\n    \n    RETURN:\n    Image - The translated image ensuring full visibility.\n    '''\n    # Calculate the translation offset needed\n    width, height = new_size\n    # Create a new image with a transparent background to accommodate the translation\n    translated_img = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n    # Paste the rotated image into the new image\n    translated_img.paste(image, (0, 0), image)\n    return translated_img\n\n",
        "answer": "'''\nThis function will calculate the necessary translation to ensure the entire rotated image is visible,\nadjusting its position accordingly.\n\nARGUMENTS:\nimage: Image - The rotated image to be translated.\nnew_size: tuple - The new dimensions (width, height) of the rotated image.\n\nRETURN:\nImage - The translated image ensuring full visibility.\n'''\ndef translate_image(image: Image, new_size: tuple) -> Image:\n    # Calculate the translation offset needed\n    width, height = new_size\n    # Create a new image with a transparent background to accommodate the translation\n    translated_img = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n    # Calculate the position to paste the rotated image to center it\n    offset_x = (width - image.width) // 2\n    offset_y = (height - image.height) // 2\n    # Paste the rotated image into the new image with the calculated offsets\n    translated_img.paste(image, (offset_x, offset_y), image)\n    return translated_img"
    },
    {
        "requirement": "def apply_affine_transformation(image: np.ndarray, dx: int = 30, dy: int = 30) -> np.ndarray:\n    '''\n    This function will perform the affine transformation on the loaded image to skew it using specified dx and dy values.\n    ARGUMENTS: \n    - image: np.ndarray - The image to be transformed.\n    - dx: int - The value of skewing in the x direction (default is 30).\n    - dy: int - The value of skewing in the y direction (default is 30).\n    \n    RETURN: \n    - np.ndarray - The skewed image after applying the affine transformation.\n    '''\n    # Get the dimensions of the image\n    height, width = image.shape[:2]\n    \n    # Define the affine transformation matrix for skewing\n    # The transformation matrix is defined as:\n    # | 1  dx/height  0 |\n    # | dy/width  1  0 |\n    # Using numpy to create the matrix\n    transformation_matrix = np.float32([[1, dx / height, 0], [dy / width, 1, 0]])\n    \n    # Apply the affine transformation to the image\n    transformed_image = cv2.warpAffine(image, transformation_matrix, (width, height))\n    \n    # Return the skewed image\n    return transformed_image\n\n",
        "answer": "'''\nThis function will perform the affine transformation on the loaded image to skew it using specified dx and dy values.\nARGUMENTS: \n- image: np.ndarray - The image to be transformed.\n- dx: int - The value of skewing in the x direction (default is 30).\n- dy: int - The value of skewing in the y direction (default is 30).\n\nRETURN: \n- np.ndarray - The skewed image after applying the affine transformation.\n'''\ndef apply_affine_transformation(image: np.ndarray, dx: int = 30, dy: int = 30) -> np.ndarray:\n    # Get the dimensions of the image\n    height, width = image.shape[:2]\n    \n    # Define the affine transformation matrix for skewing\n    # The transformation matrix is defined as:\n    # | 1  dx/height  0 |\n    # | dy/width  1  0 |\n    # Using numpy to create the matrix\n    transformation_matrix = np.float32([[1, dx / height, 0], [dy / width, 1, 0]])\n    \n    # Apply the affine transformation to the image\n    transformed_image = cv2.warpAffine(image, transformation_matrix, (width, height))\n    \n    # Return the skewed image\n    return transformed_image"
    },
    {
        "requirement": "def compute_dft(image: np.ndarray) -> np.ndarray:\n    '''\n    This function will implement the two-dimensional Discrete Fourier Transform \n    algorithm to process the input grayscale image, generating the frequency \n    representation of the image.\n    \n    ARGUMENTS: \n    image: np.ndarray - The input grayscale image in NumPy array format.\n    \n    RETURN: \n    np.ndarray - The computed DFT of the input image.\n    '''\n    # TODO: Compute the DFT using numpy's FFT functions\n    dft_image = np.fft.fft2(image)\n    return dft_image\n",
        "answer": "'''\nThis function will implement the two-dimensional Discrete Fourier Transform \nalgorithm to process the input grayscale image, generating the frequency \nrepresentation of the image.\n\nARGUMENTS: \nimage: np.ndarray - The input grayscale image in NumPy array format.\n\nRETURN: \nnp.ndarray - The computed DFT of the input image.\n'''\nimport numpy as np\n\ndef compute_dft(image: np.ndarray) -> np.ndarray:\n    dft_image = np.fft.fft2(image)\n    return dft_image"
    },
    {
        "requirement": "def display_power_spectrum(dft_image: np.ndarray) -> None:\n    '''\n    This function will calculate and display the power spectrum of the frequency \n    representation obtained from the DFT.\n    \n    ARGUMENTS: \n    dft_image: np.ndarray - The frequency representation of the image from DFT.\n    \n    RETURN: \n    None\n    '''\n    # TODO: Calculate the power spectrum and display it using matplotlib\n    power_spectrum = np.log(np.abs(dft_image) + 1)\n    plt.imshow(power_spectrum, cmap='gray')\n    plt.title('Power Spectrum')\n    plt.show()\n",
        "answer": "'''\nThis function will calculate and display the power spectrum of the frequency \nrepresentation obtained from the DFT.\n\nARGUMENTS: \ndft_image: np.ndarray - The frequency representation of the image from DFT.\n\nRETURN: \nNone\n'''\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef display_power_spectrum(dft_image: np.ndarray) -> None:\n    power_spectrum = np.log(np.abs(dft_image) + 1)\n    plt.imshow(power_spectrum, cmap='gray')\n    plt.title('Power Spectrum')\n    plt.colorbar()\n    plt.show()"
    },
    {
        "requirement": "def compute_idft(dft_image: np.ndarray) -> np.ndarray:\n    '''\n    This function will implement the two-dimensional Inverse Discrete Fourier \n    Transform algorithm to restore the original image from the frequency representation.\n    \n    ARGUMENTS: \n    dft_image: np.ndarray - The frequency representation of the image from DFT.\n    \n    RETURN: \n    np.ndarray - The restored grayscale image after applying IDFT.\n    '''\n    # TODO: Compute the IDFT using numpy's FFT functions\n    idft_image = np.fft.ifft2(dft_image)\n    return np.abs(idft_image)\n",
        "answer": "'''\nThis function will implement the two-dimensional Inverse Discrete Fourier \nTransform algorithm to restore the original image from the frequency representation.\n\nARGUMENTS: \ndft_image: np.ndarray - The frequency representation of the image from DFT.\n\nRETURN: \nnp.ndarray - The restored grayscale image after applying IDFT.\n'''\ndef compute_idft(dft_image: np.ndarray) -> np.ndarray:\n    # Compute the IDFT using numpy's FFT functions\n    idft_image = np.fft.ifft2(dft_image)\n    return np.abs(idft_image)"
    },
    {
        "requirement": "def apply_low_pass_filter(dft_image: np.ndarray, cutoff_ratio: float) -> np.ndarray:\n    '''\n    Implement a low pass filter that removes high-frequency components based on the specified cutoff distance.\n    ARGUMENTS: dft_image: np.ndarray - The DFT result of the image.\n              cutoff_ratio: float - The ratio to specify the cutoff distance in terms of the distance from the center.\n    RETURN: np.ndarray - The DFT image after applying the low pass filter.\n    '''\n    # TODO: Create a low-pass filter and apply it to the DFT result\n    rows, cols = dft_image.shape\n    crow, ccol = rows // 2, cols // 2  # Center of the image\n    r = np.sqrt(crow**2 + ccol**2)\n    mask = np.zeros((rows, cols), np.uint8)\n\n    for i in range(rows):\n        for j in range(cols):\n            dist = np.sqrt((i - crow)**2 + (j - ccol)**2)\n            if dist < 0.5 * r * cutoff_ratio:\n                mask[i, j] = 1\n\n    dft_filtered = dft_image * mask\n    return dft_filtered\n\n",
        "answer": "'''\nImplement a low pass filter that removes high-frequency components based on the specified cutoff distance.\nARGUMENTS: dft_image: np.ndarray - The DFT result of the image.\n          cutoff_ratio: float - The ratio to specify the cutoff distance in terms of the distance from the center.\nRETURN: np.ndarray - The DFT image after applying the low pass filter.\n'''\ndef apply_low_pass_filter(dft_image: np.ndarray, cutoff_ratio: float) -> np.ndarray:\n    rows, cols = dft_image.shape\n    crow, ccol = rows // 2, cols // 2  # Center of the image\n    r = np.sqrt(crow**2 + ccol**2)\n    mask = np.zeros((rows, cols), np.uint8)\n\n    for i in range(rows):\n        for j in range(cols):\n            dist = np.sqrt((i - crow)**2 + (j - ccol)**2)\n            if dist < 0.5 * r * cutoff_ratio:\n                mask[i, j] = 1\n\n    dft_filtered = dft_image * mask\n    return dft_filtered"
    },
    {
        "requirement": "def create_high_pass_filter(shape: tuple, r: float) -> np.ndarray:\n    '''\n    This function creates a high-pass filter based on the dimensions of the DFT output (shape) and the cutoff frequency calculated as 0.2r.\n    ARGUMENTS: \n    - shape: tuple - The shape of the DFT output (height, width).\n    - r: float - The distance from the center to the low frequency.\n    \n    RETURN: \n    - np.ndarray - The high-pass filter.\n    '''\n    # Generate a high-pass filter\n    center_x, center_y = shape[0] // 2, shape[1] // 2\n    y, x = np.ogrid[:shape[0], :shape[1]]\n    distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n    high_pass_filter = np.where(distance > 0.2 * r, 1, 0)\n    return high_pass_filter\n",
        "answer": "'''\nThis function creates a high-pass filter based on the dimensions of the DFT output (shape) and the cutoff frequency calculated as 0.2r.\nARGUMENTS: \n- shape: tuple - The shape of the DFT output (height, width).\n- r: float - The distance from the center to the low frequency.\n\nRETURN: \n- np.ndarray - The high-pass filter.\n'''\nimport numpy as np\n\ndef create_high_pass_filter(shape: tuple, r: float) -> np.ndarray:\n    center_x, center_y = shape[0] // 2, shape[1] // 2\n    y, x = np.ogrid[:shape[0], :shape[1]]\n    distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n    high_pass_filter = np.where(distance > 0.2 * r, 1, 0)\n    return high_pass_filter"
    },
    {
        "requirement": "def filter_frequency_components(dft_image: np.ndarray, high_pass_filter: np.ndarray) -> np.ndarray:\n    '''\n    This function applies the high-pass filter to the DFT output, removing the low frequency components and retaining the high frequency components.\n    ARGUMENTS: \n    - dft_image: np.ndarray - The DFT of the input image.\n    - high_pass_filter: np.ndarray - The high-pass filter.\n    \n    RETURN: \n    - np.ndarray - The filtered DFT image.\n    '''\n    # Apply the high-pass filter\n    filtered_image = dft_image * high_pass_filter\n    return filtered_image\n",
        "answer": "'''\nThis function applies the high-pass filter to the DFT output, removing the low frequency components and retaining the high frequency components.\nARGUMENTS: \n- dft_image: np.ndarray - The DFT of the input image.\n- high_pass_filter: np.ndarray - The high-pass filter.\n    \nRETURN: \n- np.ndarray - The filtered DFT image.\n'''\ndef filter_frequency_components(dft_image: np.ndarray, high_pass_filter: np.ndarray) -> np.ndarray:\n    # Apply the high-pass filter\n    filtered_image = dft_image * high_pass_filter\n    return filtered_image"
    },
    {
        "requirement": "def read_and_convert_to_grayscale(image_path: str) -> np.ndarray:\n    '''\n    This function reads the input image and converts it to a grayscale format.\n    \n    ARGUMENTS:\n    image_path: str - The file path to the image that needs to be read.\n    \n    RETURN:\n    np.ndarray - The grayscale image as a NumPy array.\n    '''\n    # Read the image\n    image = cv2.imread(image_path)\n    # Convert the image to grayscale\n    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return grayscale_image\n",
        "answer": "'''\nThis function reads the input image and converts it to a grayscale format.\n\nARGUMENTS:\nimage_path: str - The file path to the image that needs to be read.\n\nRETURN:\nnp.ndarray - The grayscale image as a NumPy array.\n'''\nimport cv2\nimport numpy as np\n\ndef read_and_convert_to_grayscale(image_path: str) -> np.ndarray:\n    # Read the image\n    image = cv2.imread(image_path)\n    # Check if the image has been loaded properly\n    if image is None:\n        raise FileNotFoundError(f\"The image at path {image_path} could not be found or opened.\")\n    # Convert the image to grayscale\n    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return grayscale_image"
    },
    {
        "requirement": "def apply_band_pass_filter(dft_image: np.ndarray, low_frequency: float, high_frequency: float) -> np.ndarray:\n    '''\n    This function applies a band-pass filter to isolate the frequency components between \n    0.1r and 0.5r, where r represents the distance from the center of the frequency spectrum \n    to the outer high-frequency components.\n    \n    ARGUMENTS:\n    dft_image: np.ndarray - The DFT image on which to apply the band-pass filter.\n    low_frequency: float - The low-frequency boundary.\n    high_frequency: float - The high-frequency boundary.\n    \n    RETURN:\n    np.ndarray - The filtered DFT image.\n    '''\n    # Get the dimensions of the image\n    rows, cols = dft_image.shape\n    crow, ccol = rows // 2, cols // 2  # Center coordinates\n    radius = np.sqrt(crow**2 + ccol**2)  # Distance from the center\n    \n    # Create the band-pass filter mask\n    band_pass_filter = np.zeros((rows, cols), np.float32)\n\n    for x in range(rows):\n        for y in range(cols):\n            distance = np.sqrt((x - crow)**2 + (y - ccol)**2)\n            if low_frequency * radius < distance < high_frequency * radius:\n                band_pass_filter[x, y] = 1\n\n    # Apply the band-pass filter\n    filtered_dft_image = dft_image * band_pass_filter\n    return filtered_dft_image\n",
        "answer": "'''\nThis function applies a band-pass filter to isolate the frequency components between \n0.1r and 0.5r, where r represents the distance from the center of the frequency spectrum \nto the outer high-frequency components.\n\nARGUMENTS:\ndft_image: np.ndarray - The DFT image on which to apply the band-pass filter.\nlow_frequency: float - The low-frequency boundary.\nhigh_frequency: float - The high-frequency boundary.\n\nRETURN:\nnp.ndarray - The filtered DFT image.\n'''\nimport numpy as np\n\ndef apply_band_pass_filter(dft_image: np.ndarray, low_frequency: float, high_frequency: float) -> np.ndarray:\n    # Get the dimensions of the image\n    rows, cols = dft_image.shape\n    crow, ccol = rows // 2, cols // 2  # Center coordinates\n    radius = np.sqrt(crow**2 + ccol**2)  # Distance from the center\n    \n    # Create the band-pass filter mask\n    band_pass_filter = np.zeros((rows, cols), np.float32)\n\n    for x in range(rows):\n        for y in range(cols):\n            distance = np.sqrt((x - crow)**2 + (y - ccol)**2)\n            if low_frequency * radius < distance < high_frequency * radius:\n                band_pass_filter[x, y] = 1\n\n    # Apply the band-pass filter\n    filtered_dft_image = dft_image * band_pass_filter\n    return filtered_dft_image"
    },
    {
        "requirement": "def apply_sobel_filters(image: np.ndarray) -> (np.ndarray, np.ndarray):\n    '''\n    This function will apply the Sobel filters in the x and y directions to the image to compute the edge gradients.\n    \n    ARGUMENTS:\n    image: np.ndarray - Input image on which Sobel filters are to be applied.\n\n    RETURN:\n    (sobel_x: np.ndarray, sobel_y: np.ndarray) - Returns two arrays representing the gradient in the x (sobel_x) \n    and y (sobel_y) directions.\n    '''\n    # Apply Sobel filter in the x direction\n    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n    \n    # Apply Sobel filter in the y direction\n    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n    \n    return sobel_x, sobel_y\n\n",
        "answer": "'''\nThis function will apply the Sobel filters in the x and y directions to the image to compute the edge gradients.\n\nARGUMENTS:\nimage: np.ndarray - Input image on which Sobel filters are to be applied.\n\nRETURN:\n(sobel_x: np.ndarray, sobel_y: np.ndarray) - Returns two arrays representing the gradient in the x (sobel_x) \nand y (sobel_y) directions.\n'''\nimport numpy as np\nimport cv2\n\ndef apply_sobel_filters(image: np.ndarray) -> (np.ndarray, np.ndarray):\n    # Apply Sobel filter in the x direction\n    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n    \n    # Apply Sobel filter in the y direction\n    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n    \n    return sobel_x, sobel_y"
    },
    {
        "requirement": "def compute_edge_magnitude(sobel_x: np.ndarray, sobel_y: np.ndarray) -> np.ndarray:\n    '''\n    This function will calculate the edge magnitude from the x and y gradients obtained from the Sobel filters.\n    \n    ARGUMENTS:\n    sobel_x: np.ndarray - Gradient in the x direction obtained from the Sobel filter.\n    sobel_y: np.ndarray - Gradient in the y direction obtained from the Sobel filter.\n\n    RETURN:\n    edge_magnitude: np.ndarray - Returns an array representing the magnitude of edges.\n    '''\n    # Calculate magnitude of edges using Euclidean distance formula\n    edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n    \n    return edge_magnitude\n\n",
        "answer": "'''\nThis function will calculate the edge magnitude from the x and y gradients obtained from the Sobel filters.\n\nARGUMENTS:\nsobel_x: np.ndarray - Gradient in the x direction obtained from the Sobel filter.\nsobel_y: np.ndarray - Gradient in the y direction obtained from the Sobel filter.\n\nRETURN:\nedge_magnitude: np.ndarray - Returns an array representing the magnitude of edges.\n'''\ndef compute_edge_magnitude(sobel_x: np.ndarray, sobel_y: np.ndarray) -> np.ndarray:\n    # Calculate magnitude of edges using Euclidean distance formula\n    edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n    \n    return edge_magnitude"
    },
    {
        "requirement": "def compute_edge_slope(sobel_x: np.ndarray, sobel_y: np.ndarray) -> np.ndarray:\n    '''\n    This function will determine the edge slope (direction) based on the x and y gradients.\n    \n    ARGUMENTS:\n    sobel_x: np.ndarray - Gradient in the x direction obtained from the Sobel filter.\n    sobel_y: np.ndarray - Gradient in the y direction obtained from the Sobel filter.\n\n    RETURN:\n    edge_slope: np.ndarray - Returns an array representing the angle (slope) of edges in radians.\n    '''\n    # Calculate edge direction using arctangent\n    edge_slope = np.arctan2(sobel_y, sobel_x)\n    \n    return edge_slope\n```\n\n### Summary\n- **External Libraries Used**:\n  - `numpy` for numerical operations.\n  - `cv2` (OpenCV) for applying the Sobel filter functions.\n- **Function Details**:\n  - `apply_sobel_filters`: applies the Sobel filters and returns the gradients.\n  - `compute_edge_magnitude`: computes the magnitude of edges based on the gradients.\n  - `compute_edge_slope`: determines the direction of edges based on the gradients. \n\nYou can assign these functions to the Development Groups for implementation.",
        "answer": "'''\nThis function will determine the edge slope (direction) based on the x and y gradients.\n\nARGUMENTS:\nsobel_x: np.ndarray - Gradient in the x direction obtained from the Sobel filter.\nsobel_y: np.ndarray - Gradient in the y direction obtained from the Sobel filter.\n\nRETURN:\nedge_slope: np.ndarray - Returns an array representing the angle (slope) of edges in radians.\n'''\ndef compute_edge_slope(sobel_x: np.ndarray, sobel_y: np.ndarray) -> np.ndarray:\n    # Calculate edge direction using arctangent\n    edge_slope = np.arctan2(sobel_y, sobel_x)\n    \n    return edge_slope"
    },
    {
        "requirement": "def apply_hysteresis_thresholding(edge_magnitude: np.ndarray, high_threshold: float, low_threshold: float) -> np.ndarray:\n    '''\n    This function will implement the hysteresis thresholding technique, taking in the edge magnitude image and applying high and low threshold values to detect strong and weak edges.\n    It will ensure weak edges are retained only if they are connected to strong edges.\n    ARGUMENTS: \n    - edge_magnitude: np.ndarray - The image containing edge magnitudes.\n    - high_threshold: float - The threshold value above which edges are considered strong.\n    - low_threshold: float - The threshold value below which edges are considered weak.\n    RETURN: np.ndarray - The image with edges identified, retaining strong and connected weak edges.\n    '''\n    # TODO: Implement hysteresis thresholding algorithm\n```\n\n```python",
        "answer": "'''\nThis function will implement the hysteresis thresholding technique, taking in the edge magnitude image and applying high and low threshold values to detect strong and weak edges.\nIt will ensure weak edges are retained only if they are connected to strong edges.\nARGUMENTS: \n- edge_magnitude: np.ndarray - The image containing edge magnitudes.\n- high_threshold: float - The threshold value above which edges are considered strong.\n- low_threshold: float - The threshold value below which edges are considered weak.\nRETURN: np.ndarray - The image with edges identified, retaining strong and connected weak edges.\n'''\nimport numpy as np\n\ndef apply_hysteresis_thresholding(edge_magnitude: np.ndarray, high_threshold: float, low_threshold: float) -> np.ndarray:\n    # Create a binary image from edge magnitudes\n    strong_edges = (edge_magnitude >= high_threshold).astype(np.uint8)\n    weak_edges = ((edge_magnitude >= low_threshold) & (edge_magnitude < high_threshold)).astype(np.uint8)\n\n    # Create an output image\n    output = np.zeros_like(edge_magnitude, dtype=np.uint8)\n\n    # Label the strong edges\n    output[strong_edges == 1] = 255\n\n    # Get the indices of strong edges\n    strong_indices = np.argwhere(strong_edges == 1)\n\n    # Define an 8-connected neighborhood\n    for y, x in strong_indices:\n        # Check the 8-connected neighbors\n        for dy in [-1, 0, 1]:\n            for dx in [-1, 0, 1]:\n                if dy == 0 and dx == 0:\n                    continue\n                ny, nx = y + dy, x + dx\n                if (0 <= ny < edge_magnitude.shape[0]) and (0 <= nx < edge_magnitude.shape[1]):\n                    if weak_edges[ny, nx] == 1:\n                        output[ny, nx] = 255\n\n    return output"
    },
    {
        "requirement": "def create_thresholds(edge_magnitude: np.ndarray) -> Tuple[float, float]:\n    '''\n    This function will compute the high and low threshold values based on the edge magnitude image,\n    possibly using methods such as Otsu's method or simple percentage-based thresholds from the maximum magnitude value.\n    ARGUMENTS: \n    - edge_magnitude: np.ndarray - The image containing edge magnitudes.\n    RETURN: Tuple[float, float] - The computed high and low threshold values.\n    '''\n    # TODO: Implement threshold computation logic\n```\n\n```python",
        "answer": "'''\nThis function will compute the high and low threshold values based on the edge magnitude image,\npossibly using methods such as Otsu's method or simple percentage-based thresholds from the maximum magnitude value.\nARGUMENTS: \n- edge_magnitude: np.ndarray - The image containing edge magnitudes.\nRETURN: Tuple[float, float] - The computed high and low threshold values.\n'''\nimport numpy as np\nfrom skimage.filters import threshold_otsu\nfrom typing import Tuple\n\ndef create_thresholds(edge_magnitude: np.ndarray) -> Tuple[float, float]:\n    # Calculate the maximum magnitude value\n    max_magnitude = np.max(edge_magnitude)\n    \n    # Compute the Otsu's threshold\n    otsu_threshold = threshold_otsu(edge_magnitude)\n    \n    # Define low and high thresholds\n    low_threshold = otsu_threshold * 0.5  # Example: Low threshold as 50% of Otsu's threshold\n    high_threshold = otsu_threshold * 1.5  # Example: High threshold as 150% of Otsu's threshold\n    \n    # Optionally clamp thresholds to the image range\n    low_threshold = max(0, min(low_threshold, max_magnitude))\n    high_threshold = max(0, min(high_threshold, max_magnitude))\n    \n    return low_threshold, high_threshold"
    },
    {
        "requirement": "def finalize_edges(edge_detected_image: np.ndarray, hysteresis_result: np.ndarray) -> np.ndarray:\n    '''\n    This function will finalize the edge detected image by combining the results of the hysteresis thresholding process\n    and preparing the output for visualization/display/storage.\n    ARGUMENTS: \n    - edge_detected_image: np.ndarray - The image containing initial edge detections.\n    - hysteresis_result: np.ndarray - The result from the hysteresis thresholding process.\n    RETURN: np.ndarray - The finalized edge-detected image ready for output.\n    '''\n    # TODO: Implement logic to finalize and prepare the output image\n```\n\n### External Libraries to be Used:\n- `numpy` (import as `np`): For handling array operations and manipulations.\n- Optionally, you might consider using `cv2` (OpenCV) for easier thresholding implementations\u2014especially in `create_thresholds`, depending on the chosen method.",
        "answer": "'''\nThis function will finalize the edge detected image by combining the results of the hysteresis thresholding process\nand preparing the output for visualization/display/storage.\nARGUMENTS: \n- edge_detected_image: np.ndarray - The image containing initial edge detections.\n- hysteresis_result: np.ndarray - The result from the hysteresis thresholding process.\nRETURN: np.ndarray - The finalized edge-detected image ready for output.\n'''\nimport numpy as np\n\ndef finalize_edges(edge_detected_image: np.ndarray, hysteresis_result: np.ndarray) -> np.ndarray:\n    # Ensure both input images have the same shape\n    if edge_detected_image.shape != hysteresis_result.shape:\n        raise ValueError(\"Input images must have the same dimensions.\")\n    \n    # Use the hysteresis result to mask the initial edge-detected image\n    finalized_image = np.where(hysteresis_result > 0, edge_detected_image, 0)\n\n    # Convert the finalized image to uint8 for proper display\n    finalized_image = (finalized_image * 255).astype(np.uint8)\n\n    return finalized_image"
    },
    {
        "requirement": "def apply_gaussian_filter(image: np.ndarray, kernel_size: int = 5, sigma: float = 1.0) -> np.ndarray:\n    '''\n    Applies a Gaussian filter to the loaded image to smooth it.\n    ARGUMENTS: \n        image: np.ndarray - The input image to be filtered.\n        kernel_size: int - The size of the Gaussian kernel (must be odd).\n        sigma: float - The standard deviation of the Gaussian distribution.\n    RETURN: \n        np.ndarray - The smoothed image after applying Gaussian filter.\n    '''\n    # TODO: Implement Gaussian filtering using OpenCV\n    smoothed_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n    return smoothed_image\n\n",
        "answer": "'''\nApplies a Gaussian filter to the loaded image to smooth it.\nARGUMENTS: \n    image: np.ndarray - The input image to be filtered.\n    kernel_size: int - The size of the Gaussian kernel (must be odd).\n    sigma: float - The standard deviation of the Gaussian distribution.\nRETURN: \n    np.ndarray - The smoothed image after applying Gaussian filter.\n'''\nimport numpy as np\nimport cv2\n\ndef apply_gaussian_filter(image: np.ndarray, kernel_size: int = 5, sigma: float = 1.0) -> np.ndarray:\n    smoothed_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n    return smoothed_image"
    },
    {
        "requirement": "def perform_non_maximum_suppression(gradients: np.ndarray, directions: np.ndarray) -> np.ndarray:\n    '''\n    This function takes the edge gradient values and their corresponding directions as input\n    and thins the edges by applying non-maximum suppression to retain only the local maxima \n    in the gradient direction, effectively highlighting the strongest edges.\n    \n    ARGUMENTS:\n    gradients: np.ndarray - A 2D array containing the edge gradient values.\n    directions: np.ndarray - A 2D array containing the edge directions corresponding to the gradients.\n    \n    RETURN: np.ndarray - A 2D array with non-maximum suppressed edge values.\n    '''\n    # TODO: Implement non-maximum suppression logic here\n    pass  \n\n",
        "answer": "'''\nThis function takes the edge gradient values and their corresponding directions as input\nand thins the edges by applying non-maximum suppression to retain only the local maxima \nin the gradient direction, effectively highlighting the strongest edges.\n\nARGUMENTS:\ngradients: np.ndarray - A 2D array containing the edge gradient values.\ndirections: np.ndarray - A 2D array containing the edge directions corresponding to the gradients.\n\nRETURN: np.ndarray - A 2D array with non-maximum suppressed edge values.\n'''\nimport numpy as np\n\ndef perform_non_maximum_suppression(gradients: np.ndarray, directions: np.ndarray) -> np.ndarray:\n    # Get the dimensions of the gradients array\n    rows, cols = gradients.shape\n    output = np.zeros((rows, cols), dtype=np.float32)\n\n    # Loop over the image excluding the border pixels\n    for i in range(1, rows - 1):\n        for j in range(1, cols - 1):\n            # Angle determination (0-180 degree)\n            angle = directions[i, j] % 180\n            \n            # Initialize the neighbors\n            q = 255\n            r = 255\n            \n            # Adjust neighboring pixels based on gradient direction\n            if (0 <= angle < 22.5) or (157.5 <= angle <= 180):\n                q = gradients[i, j + 1]  # right pixel\n                r = gradients[i, j - 1]  # left pixel\n            elif (22.5 <= angle < 67.5):\n                q = gradients[i + 1, j - 1]  # bottom-left pixel\n                r = gradients[i - 1, j + 1]  # top-right pixel\n            elif (67.5 <= angle < 112.5):\n                q = gradients[i + 1, j]  # bottom pixel\n                r = gradients[i - 1, j]  # top pixel\n            elif (112.5 <= angle < 157.5):\n                q = gradients[i - 1, j - 1]  # top-left pixel\n                r = gradients[i + 1, j + 1]  # bottom-right pixel\n            \n            # Suppress the non-maximal pixels\n            if gradients[i, j] >= q and gradients[i, j] >= r:\n                output[i, j] = gradients[i, j]\n            else:\n                output[i, j] = 0\n\n    return output"
    },
    {
        "requirement": "def get_gradient_magnitude_direction(gradients: np.ndarray) -> tuple:\n    '''\n    This function calculates the gradient magnitude and direction from the edge gradients provided.\n    It prepares the necessary data for the non-maximum suppression process by transforming the \n    gradients into polar coordinates.\n    \n    ARGUMENTS:\n    gradients: np.ndarray - A 2D array containing the edge gradient values.\n    \n    RETURN: tuple - A tuple containing:\n        - np.ndarray - A 2D array of gradient magnitudes.\n        - np.ndarray - A 2D array of gradient directions.\n    '''\n    # TODO: Implement logic to calculate magnitude and direction here\n    pass  \n``` \n\nThese definitions outline the necessary functions for the EDGE_THINNING module, utilizing NumPy for numerical operations, which is essential for handling array data in the context of image processing. Please communicate these refined functions to the Development Groups for further implementation.",
        "answer": "'''\nThis function calculates the gradient magnitude and direction from the edge gradients provided.\nIt prepares the necessary data for the non-maximum suppression process by transforming the \ngradients into polar coordinates.\n\nARGUMENTS:\ngradients: np.ndarray - A 2D array containing the edge gradient values.\n\nRETURN: tuple - A tuple containing:\n    - np.ndarray - A 2D array of gradient magnitudes.\n    - np.ndarray - A 2D array of gradient directions.\n'''\n\nimport numpy as np\n\ndef get_gradient_magnitude_direction(gradients: np.ndarray) -> tuple:\n    # Calculate the gradient magnitudes using the L2 norm\n    magnitude = np.sqrt(gradients[0]**2 + gradients[1]**2)\n    \n    # Calculate the gradient directions using arctan2\n    direction = np.arctan2(gradients[1], gradients[0])\n    \n    # Convert radians to degrees for the direction, if needed\n    direction = np.degrees(direction)\n    \n    # Normalize the direction to be in the range [0, 180]\n    direction = (direction + 180) % 180\n    \n    return magnitude, direction"
    },
    {
        "requirement": "def edge_detection(image:np.ndarray) -> np.ndarray:\n    '''\n    This function will implement an edge detection algorithm (such as Canny) \n    to identify edges in the loaded image, which is a crucial step before applying \n    the Hough transformation.\n    \n    ARGUMENTS: \n    - image: np.ndarray - The input image in grayscale format.\n    \n    RETURN: \n    - np.ndarray - The edges detected in the image.\n    '''\n    # Apply Canny edge detection\n    edges = cv2.Canny(image, 100, 200)\n    return edges\n",
        "answer": "'''\nThis function will implement an edge detection algorithm (such as Canny) \nto identify edges in the loaded image, which is a crucial step before applying \nthe Hough transformation.\n\nARGUMENTS: \n- image: np.ndarray - The input image in grayscale format.\n\nRETURN: \n- np.ndarray - The edges detected in the image.\n'''\nimport cv2\nimport numpy as np\n\ndef edge_detection(image: np.ndarray) -> np.ndarray:\n    # Apply Canny edge detection\n    edges = cv2.Canny(image, 100, 200)\n    return edges"
    },
    {
        "requirement": "def hough_transform(edges:np.ndarray) -> np.ndarray:\n    '''\n    This function will carry out the Hough transformation by converting the \n    detected edges in the image into points in the parameter space (a, b), \n    as per the equation of a line y = ax + b.\n    \n    ARGUMENTS: \n    - edges: np.ndarray - The edges detected in the image.\n    \n    RETURN: \n    - np.ndarray - The accumulator array containing points in the parameter space.\n    '''\n    # Perform Hough Transform\n    h, theta, d = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n    return h\n",
        "answer": "'''\nThis function will carry out the Hough transformation by converting the \ndetected edges in the image into points in the parameter space (a, b), \nas per the equation of a line y = ax + b.\n\nARGUMENTS: \n- edges: np.ndarray - The edges detected in the image.\n\nRETURN: \n- np.ndarray - The accumulator array containing points in the parameter space.\n'''\nimport numpy as np\nimport cv2\n\ndef hough_transform(edges: np.ndarray) -> np.ndarray:\n    # Perform Hough Transform\n    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n    \n    # Create an accumulator array for the values\n    if lines is not None:\n        # Initialize the accumulator with zeros (size of parameter space)\n        max_a = int(np.ceil(np.max(edges.shape) * np.sqrt(2)))\n        max_b = max_a\n        accumulator = np.zeros((max_a * 2, max_b * 2), dtype=np.int)\n\n        for rho, theta in lines[:, 0]:\n            a = int(np.round(rho * np.cos(theta)))\n            b = int(np.round(rho * np.sin(theta)))\n            accumulator[a + max_a // 2, b + max_b // 2] += 1\n            \n        return accumulator\n    else:\n        return np.zeros((0, 0), dtype=np.int)  # No lines detected"
    },
    {
        "requirement": "def detect_lines(accumulator:np.ndarray, threshold:int) -> list:\n    '''\n    This function will analyze the accumulator array generated by the Hough \n    transformation and detect significant lines based on a defined threshold.\n    \n    ARGUMENTS: \n    - accumulator: np.ndarray - The accumulator array generated by Hough transformation.\n    - threshold: int - The minimum voting threshold for a line to be considered significant.\n    \n    RETURN: \n    - list - A list of detected lines represented by (a, b) parameters.\n    '''\n    # Extract lines using the defined threshold\n    lines = []\n    for i in range(len(accumulator)):\n        if accumulator[i][0] > threshold:\n            lines.append(accumulator[i])\n    return lines\n",
        "answer": "'''\nThis function will analyze the accumulator array generated by the Hough \ntransformation and detect significant lines based on a defined threshold.\n\nARGUMENTS: \n- accumulator: np.ndarray - The accumulator array generated by Hough transformation.\n- threshold: int - The minimum voting threshold for a line to be considered significant.\n\nRETURN: \n- list - A list of detected lines represented by (a, b) parameters.\n'''\ndef detect_lines(accumulator: np.ndarray, threshold: int) -> list:\n    lines = []\n    for i in range(accumulator.shape[0]):\n        for j in range(accumulator.shape[1]):\n            if accumulator[i, j] >= threshold:\n                lines.append((i, j))  # Assuming (i, j) corresponds to (a, b)\n    return lines"
    },
    {
        "requirement": "def draw_lines(image:np.ndarray, lines:list) -> np.ndarray:\n    '''\n    This function will visualize the detected lines on the original image \n    and save or display the result.\n    \n    ARGUMENTS: \n    - image: np.ndarray - The original input image.\n    - lines: list - The detected lines represented by (a, b) parameters.\n    \n    RETURN: \n    - np.ndarray - The image with detected lines drawn on it.\n    '''\n    # Draw lines on the image\n    for line in lines:\n        a, b = line[0], line[1]\n        x0 = (b - 0) / a\n        x1 = (b - image.shape[0]) / a\n        cv2.line(image, (int(x0), 0), (int(x1), image.shape[0]), (0, 255, 0), 2)\n    return image\n```\n\n### Summary of Functionality:\n1. **load_image**: Loads and converts the image to grayscale.\n2. **edge_detection**: Identifies edges in the grayscale image using Canny edge detection.\n3. **hough_transform**: Converts detected edges into the parameter space for line detection.\n4. **detect_lines**: Identifies significant lines from the accumulator using a threshold.\n5. **draw_lines**: Draws the detected lines onto the original image for visualization. \n\nNext, I will delegate these functions to the appropriate Development Groups for implementation.",
        "answer": "'''\nThis function will visualize the detected lines on the original image \nand save or display the result.\n\nARGUMENTS: \n- image: np.ndarray - The original input image.\n- lines: list - The detected lines represented by (a, b) parameters.\n\nRETURN: \n- np.ndarray - The image with detected lines drawn on it.\n'''\nimport numpy as np\nimport cv2\n\ndef draw_lines(image: np.ndarray, lines: list) -> np.ndarray:\n    # Draw lines on the image\n    for line in lines:\n        a, b = line[0], line[1]\n        # Calculate the starting and ending points for the line based on the image dimensions\n        if a != 0:  # Avoid division by zero\n            x0 = (b - 0) / a\n            x1 = (b - image.shape[0]) / a\n            # Draw the line on the image\n            cv2.line(image, (int(x0), 0), (int(x1), image.shape[0]), (0, 255, 0), 2)\n    return image"
    },
    {
        "requirement": "def apply_dilation(binary_image: np.ndarray, kernel_size: int) -> np.ndarray:\n    '''\n    Performs the morphological dilation operation on the loaded binary image using a defined kernel size.\n    \n    ARGUMENTS:\n    binary_image: np.ndarray - The input binary image as a NumPy array.\n    kernel_size: int - The size of the dilation kernel.\n    \n    RETURN: np.ndarray - The dilated image as a NumPy array.\n    '''\n    # TODO: Create a structuring element (kernel) and apply dilation using cv2.dilate\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    dilated_image = cv2.dilate(binary_image, kernel, iterations=1)\n    return dilated_image\n\n",
        "answer": "'''\nPerforms the morphological dilation operation on the loaded binary image using a defined kernel size.\n\nARGUMENTS:\nbinary_image: np.ndarray - The input binary image as a NumPy array.\nkernel_size: int - The size of the dilation kernel.\n\nRETURN: np.ndarray - The dilated image as a NumPy array.\n'''\nimport numpy as np\nimport cv2\n\ndef apply_dilation(binary_image: np.ndarray, kernel_size: int) -> np.ndarray:\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    dilated_image = cv2.dilate(binary_image, kernel, iterations=1)\n    return dilated_image"
    },
    {
        "requirement": "def apply_erosion(image: np.ndarray, kernel_size: int) -> np.ndarray:\n    '''\n    Applies the morphological erosion operation on the binarized image using the specified kernel size.\n    \n    ARGUMENTS:\n    image: np.ndarray - The input binarized image as a NumPy array.\n    kernel_size: int - The size of the kernel used for the erosion operation (must be an odd integer).\n    \n    RETURN:\n    np.ndarray - The eroded image as a NumPy array.\n    '''\n    # TODO: Implement morphological erosion using OpenCV\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)  # Create a square kernel\n    eroded_image = cv2.erode(image, kernel, iterations=1)  # Apply erosion\n    return eroded_image\n\n",
        "answer": "'''\nApplies the morphological erosion operation on the binarized image using the specified kernel size.\n\nARGUMENTS:\nimage: np.ndarray - The input binarized image as a NumPy array.\nkernel_size: int - The size of the kernel used for the erosion operation (must be an odd integer).\n\nRETURN:\nnp.ndarray - The eroded image as a NumPy array.\n'''\ndef apply_erosion(image: np.ndarray, kernel_size: int) -> np.ndarray:\n    import numpy as np\n    import cv2\n    \n    # Create a square kernel of the specified size\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    \n    # Apply the erosion operation\n    eroded_image = cv2.erode(image, kernel, iterations=1)\n    \n    return eroded_image"
    },
    {
        "requirement": "def DILATE_IMAGE(image: np.ndarray, kernel_size: int = 3) -> np.ndarray:\n    '''\n    Apply the dilation operation to the loaded image to expand the white regions \n    and potentially fill small holes in the foreground.\n    \n    ARGUMENTS:\n    - image: np.ndarray - The input binary image to be dilated.\n    - kernel_size: int - The size of the structuring element used for dilation (default is 3).\n\n    RETURN: np.ndarray - The dilated binary image.\n    '''\n    # Create a structuring element\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    # Apply dilation\n    dilated_image = cv2.dilate(image, kernel, iterations=1)\n    return dilated_image\n",
        "answer": "'''\nApply the dilation operation to the loaded image to expand the white regions \nand potentially fill small holes in the foreground.\n\nARGUMENTS:\n- image: np.ndarray - The input binary image to be dilated.\n- kernel_size: int - The size of the structuring element used for dilation (default is 3).\n\nRETURN: np.ndarray - The dilated binary image.\n'''\ndef DILATE_IMAGE(image: np.ndarray, kernel_size: int = 3) -> np.ndarray:\n    import numpy as np\n    import cv2\n    \n    # Create a structuring element\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    # Apply dilation\n    dilated_image = cv2.dilate(image, kernel, iterations=1)\n    return dilated_image"
    },
    {
        "requirement": "def ERODE_IMAGE(image: np.ndarray, kernel_size: int = 3) -> np.ndarray:\n    '''\n    Apply the erosion operation to the dilated image to remove small-scale noise \n    and reduce the size of the white regions. \n\n    ARGUMENTS:\n    - image: np.ndarray - The input binary image to be eroded.\n    - kernel_size: int - The size of the structuring element used for erosion (default is 3).\n\n    RETURN: np.ndarray - The eroded binary image.\n    '''\n    # Create a structuring element\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    # Apply erosion\n    eroded_image = cv2.erode(image, kernel, iterations=1)\n    return eroded_image\n",
        "answer": "'''\nApply the erosion operation to the dilated image to remove small-scale noise \nand reduce the size of the white regions. \n\nARGUMENTS:\n- image: np.ndarray - The input binary image to be eroded.\n- kernel_size: int - The size of the structuring element used for erosion (default is 3).\n\nRETURN: np.ndarray - The eroded binary image.\n'''\nimport cv2\nimport numpy as np\n\ndef ERODE_IMAGE(image: np.ndarray, kernel_size: int = 3) -> np.ndarray:\n    # Create a structuring element\n    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n    # Apply erosion\n    eroded_image = cv2.erode(image, kernel, iterations=1)\n    return eroded_image"
    },
    {
        "requirement": "def closing_operation(binary_image: np.ndarray, kernel_size: int) -> np.ndarray:\n    '''\n    Combine the erosion and dilation operations to achieve the closing effect on the original binary image.\n    ARGUMENTS: \n        binary_image: np.ndarray - The original binary image.\n        kernel_size: int - Size of the structuring element for performing closing.\n    RETURN: \n        np.ndarray - The image after performing the closing operation.\n    '''\n    # TODO: Implement the closing operation\n    eroded_image = perform_erosion(binary_image, kernel_size)\n    closed_image = perform_dilation(eroded_image, kernel_size)\n    return closed_image\n",
        "answer": "'''\nCombine the erosion and dilation operations to achieve the closing effect on the original binary image.\nARGUMENTS: \n    binary_image: np.ndarray - The original binary image.\n    kernel_size: int - Size of the structuring element for performing closing.\nRETURN: \n    np.ndarray - The image after performing the closing operation.\n'''\nimport numpy as np\nfrom scipy.ndimage import binary_erosion, binary_dilation\n\ndef perform_erosion(binary_image: np.ndarray, kernel_size: int) -> np.ndarray:\n    # Create a structuring element\n    structuring_element = np.ones((kernel_size, kernel_size), dtype=np.uint8)\n    # Perform erosion\n    eroded_image = binary_erosion(binary_image, structure=structuring_element).astype(np.uint8)\n    return eroded_image\n\ndef perform_dilation(binary_image: np.ndarray, kernel_size: int) -> np.ndarray:\n    # Create a structuring element\n    structuring_element = np.ones((kernel_size, kernel_size), dtype=np.uint8)\n    # Perform dilation\n    dilated_image = binary_dilation(binary_image, structure=structuring_element).astype(np.uint8)\n    return dilated_image\n\ndef closing_operation(binary_image: np.ndarray, kernel_size: int) -> np.ndarray:\n    eroded_image = perform_erosion(binary_image, kernel_size)\n    closed_image = perform_dilation(eroded_image, kernel_size)\n    return closed_image"
    },
    {
        "requirement": "def compute_gradient(dilated_image: np.ndarray, eroded_image: np.ndarray) -> np.ndarray:\n    '''\n    This function will take the dilated image and the eroded image as inputs and compute the gradient image by subtracting the eroded image from the dilated image.\n    ARGUMENTS: dilated_image: np.ndarray  # Image obtained after the dilation operation.\n               eroded_image: np.ndarray  # Eroded image.\n    RETURN: np.ndarray  # Gradient image.\n    '''\n    gradient_image = cv2.subtract(dilated_image, eroded_image)  # Compute the gradient by subtracting\n    return gradient_image\n```\n\nThese definitions include detailed descriptions, argument types, and return types for each function, complying with the project requirement. You can now delegate these functions to the Development Groups for implementation.",
        "answer": "'''\nThis function will take the dilated image and the eroded image as inputs and compute the gradient image by subtracting the eroded image from the dilated image.\nARGUMENTS: dilated_image: np.ndarray  # Image obtained after the dilation operation.\n           eroded_image: np.ndarray  # Eroded image.\nRETURN: np.ndarray  # Gradient image.\n'''\ndef compute_gradient(dilated_image: np.ndarray, eroded_image: np.ndarray) -> np.ndarray:\n    gradient_image = cv2.subtract(dilated_image, eroded_image)  # Compute the gradient by subtracting\n    return gradient_image"
    },
    {
        "requirement": "def apply_morphological_opening(image: np.ndarray, kernel_size: int) -> np.ndarray:\n    '''\n    This function applies the morphological opening operation on the \n    loaded image to remove small objects and noise from the image.\n    \n    ARGUMENTS:\n    image: np.ndarray - The original image on which to apply the opening.\n    kernel_size: int - The size of the kernel to be used for the opening operation.\n\n    RETURN: np.ndarray - The image after morphological opening has been applied.\n    '''\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))  # Create kernel\n    opened_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)  # Apply morphological opening\n    return opened_image\n",
        "answer": "'''\nThis function applies the morphological opening operation on the \nloaded image to remove small objects and noise from the image.\n\nARGUMENTS:\nimage: np.ndarray - The original image on which to apply the opening.\nkernel_size: int - The size of the kernel to be used for the opening operation.\n\nRETURN: np.ndarray - The image after morphological opening has been applied.\n'''\nimport numpy as np\nimport cv2\n\ndef apply_morphological_opening(image: np.ndarray, kernel_size: int) -> np.ndarray:\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))  # Create kernel\n    opened_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)  # Apply morphological opening\n    return opened_image"
    },
    {
        "requirement": "def subtract_opened_image(original_image: np.ndarray, opened_image: np.ndarray) -> np.ndarray:\n    '''\n    This function subtracts the opened image obtained from the previous \n    function from the original image to highlight the bright regions.\n    \n    ARGUMENTS:\n    original_image: np.ndarray - The original image.\n    opened_image: np.ndarray - The image obtained after the opening operation.\n\n    RETURN: np.ndarray - The resulting image highlighting the bright regions.\n    '''\n    result_image = cv2.subtract(original_image, opened_image)  # Subtract opened image from original\n    return result_image\n",
        "answer": "'''\nThis function subtracts the opened image obtained from the previous \nfunction from the original image to highlight the bright regions.\n\nARGUMENTS:\noriginal_image: np.ndarray - The original image.\nopened_image: np.ndarray - The image obtained after the opening operation.\n\nRETURN: np.ndarray - The resulting image highlighting the bright regions.\n'''\ndef subtract_opened_image(original_image: np.ndarray, opened_image: np.ndarray) -> np.ndarray:\n    result_image = cv2.subtract(original_image, opened_image)  # Subtract opened image from original\n    return result_image"
    },
    {
        "requirement": "def apply_closing(binary_image:np.ndarray) -> np.ndarray:\n    '''\n    Apply morphological closing on the binarized image.\n    ARGUMENTS: \n    binary_image: np.ndarray - The binarized image to be processed.\n    RETURN: \n    np.ndarray - The image after applying the morphological closing operation.\n    '''\n    # Define a kernel for morphological operations\n    kernel = np.ones((5, 5), np.uint8)\n    # Apply morphological closing\n    closed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n    return closed_image\n",
        "answer": "'''\nApply morphological closing on the binarized image.\nARGUMENTS: \nbinary_image: np.ndarray - The binarized image to be processed.\nRETURN: \nnp.ndarray - The image after applying the morphological closing operation.\n'''\nimport cv2\nimport numpy as np\n\ndef apply_closing(binary_image: np.ndarray) -> np.ndarray:\n    # Define a kernel for morphological operations\n    kernel = np.ones((5, 5), np.uint8)\n    # Apply morphological closing\n    closed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n    return closed_image"
    },
    {
        "requirement": "def compute_black_hat(closed_image:np.ndarray, binary_image:np.ndarray) -> np.ndarray:\n    '''\n    Compute the Black-Hat filter by subtracting the original binarized image from the closed image.\n    ARGUMENTS: \n    closed_image: np.ndarray - The result of the closing operation.\n    binary_image: np.ndarray - The original binarized image.\n    RETURN: \n    np.ndarray - The resulting image after applying the Black-Hat filter.\n    '''\n    # Subtract the binarized image from the closed image\n    black_hat_image = cv2.subtract(closed_image, binary_image)\n    return black_hat_image\n",
        "answer": "'''\nCompute the Black-Hat filter by subtracting the original binarized image from the closed image.\nARGUMENTS: \nclosed_image: np.ndarray - The result of the closing operation.\nbinary_image: np.ndarray - The original binarized image.\nRETURN: \nnp.ndarray - The resulting image after applying the Black-Hat filter.\n'''\ndef compute_black_hat(closed_image: np.ndarray, binary_image: np.ndarray) -> np.ndarray:\n    # Subtract the binarized image from the closed image\n    black_hat_image = cv2.subtract(closed_image, binary_image)\n    return black_hat_image"
    },
    {
        "requirement": "def calculate_squared_differences(input_image: np.ndarray, reference_image: np.ndarray) -> np.ndarray:\n    '''\n    Compute the squared differences between the pixel values of the input image and the reference image.\n    ARGUMENTS: input_image: np.ndarray - The input image as a NumPy array.\n               reference_image: np.ndarray - The reference image as a NumPy array.\n    RETURN: np.ndarray - A new array containing the squared differences between the two images.\n    '''\n    # TODO: Implement the calculation of squared differences\n    squared_differences = (input_image.astype(np.float32) - reference_image.astype(np.float32)) ** 2\n    return squared_differences\n",
        "answer": "'''\nCompute the squared differences between the pixel values of the input image and the reference image.\nARGUMENTS: input_image: np.ndarray - The input image as a NumPy array.\n           reference_image: np.ndarray - The reference image as a NumPy array.\nRETURN: np.ndarray - A new array containing the squared differences between the two images.\n'''\nimport numpy as np\n\ndef calculate_squared_differences(input_image: np.ndarray, reference_image: np.ndarray) -> np.ndarray:\n    squared_differences = (input_image.astype(np.float32) - reference_image.astype(np.float32)) ** 2\n    return squared_differences"
    },
    {
        "requirement": "def sum_squared_differences(squared_differences: np.ndarray) -> float:\n    '''\n    Calculate the sum of the squared differences obtained from the previous function.\n    ARGUMENTS: squared_differences: np.ndarray - The squared differences array.\n    RETURN: float - The sum of the squared differences.\n    '''\n    # TODO: Implement the summation of squared differences\n    return np.sum(squared_differences)\n",
        "answer": "'''\nCalculate the sum of the squared differences obtained from the previous function.\nARGUMENTS: squared_differences: np.ndarray - The squared differences array.\nRETURN: float - The sum of the squared differences.\n'''\ndef sum_squared_differences(squared_differences: np.ndarray) -> float:\n    return np.sum(squared_differences)"
    },
    {
        "requirement": "def ssd_matching(input_image_path: str, reference_image: np.ndarray) -> float:\n    '''\n    Main function to perform the SSD matching, orchestrating the loading of images, calculation of squared differences, and summation of those differences.\n    ARGUMENTS: input_image_path: str - The path to the input image file.\n               reference_image: np.ndarray - The reference image as a NumPy array.\n    RETURN: float - The total sum of squared differences.\n    '''\n    # TODO: Implement the SSD matching process\n    input_image = load_image(input_image_path)\n    squared_differences = calculate_squared_differences(input_image, reference_image)\n    return sum_squared_differences(squared_differences)\n```\n\nIn this pseudo code:\n- The `cv2` library from OpenCV is used to load images, while `numpy` is utilized for numerical operations and array manipulations.\n- Each function includes a detailed description of its purpose, the arguments it takes, and the return type. \n- The `TODO` comment indicates where the implementation should be filled in during actual coding.",
        "answer": "'''\nMain function to perform the SSD matching, orchestrating the loading of images, calculation of squared differences, and summation of those differences.\nARGUMENTS: input_image_path: str - The path to the input image file.\n           reference_image: np.ndarray - The reference image as a NumPy array.\nRETURN: float - The total sum of squared differences.\n'''\nimport cv2\nimport numpy as np\n\ndef ssd_matching(input_image_path: str, reference_image: np.ndarray) -> float:\n    # Load the input image using OpenCV\n    input_image = load_image(input_image_path)\n    \n    # Calculate squared differences between input and reference images\n    squared_differences = calculate_squared_differences(input_image, reference_image)\n    \n    # Sum and return the total sum of squared differences\n    return sum_squared_differences(squared_differences)\n\ndef load_image(image_path: str) -> np.ndarray:\n    # Load the image using OpenCV and convert it to grayscale\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    if image is None:\n        raise FileNotFoundError(f\"The image at path {image_path} could not be found.\")\n    return image\n\ndef calculate_squared_differences(input_image: np.ndarray, reference_image: np.ndarray) -> np.ndarray:\n    # Ensure both images are of the same shape\n    if input_image.shape != reference_image.shape:\n        raise ValueError(\"Input image and reference image must have the same dimensions.\")\n    \n    # Calculate squared differences\n    return np.square(input_image.astype(np.float32) - reference_image.astype(np.float32))\n\ndef sum_squared_differences(squared_differences: np.ndarray) -> float:\n    # Sum all the squared differences and return the total\n    return np.sum(squared_differences)"
    },
    {
        "requirement": "def calculate_sad(image1: Image.Image, image2: Image.Image) -> float:\n    '''\n    Calculate the sum of absolute differences between the pixel values of the two loaded images.\n    ARGUMENTS:\n    - image1: Image.Image - The first image loaded from file.\n    - image2: Image.Image - The second image loaded from file.\n    RETURN: float - The calculated sum of absolute differences.\n    '''\n    # TODO: Implement the SAD calculation logic\n    \n",
        "answer": "'''\nCalculate the sum of absolute differences between the pixel values of the two loaded images.\nARGUMENTS:\n- image1: Image.Image - The first image loaded from file.\n- image2: Image.Image - The second image loaded from file.\nRETURN: float - The calculated sum of absolute differences.\n'''\nfrom PIL import Image\nimport numpy as np\n\ndef calculate_sad(image1: Image.Image, image2: Image.Image) -> float:\n    if image1.size != image2.size:\n        raise ValueError(\"Images must be of the same dimensions.\")\n    \n    # Convert images to numpy arrays for easier pixel value manipulation\n    img1_array = np.asarray(image1, dtype=np.float32)\n    img2_array = np.asarray(image2, dtype=np.float32)\n    \n    # Calculate the sum of absolute differences\n    sad = np.sum(np.abs(img1_array - img2_array))\n    \n    return sad"
    },
    {
        "requirement": "def display_results(sad_value: float) -> None:\n    '''\n    Display the calculated SAD value for the user.\n    ARGUMENTS:\n    - sad_value: float - The calculated sum of absolute differences between the two images.\n    RETURN: None\n    '''\n    # TODO: Implement the result display logic\n```\n\n### Notes:\n- **PIL (Python Imaging Library)** is used for image handling, specifically for loading images.\n- **NumPy** may be used for efficient array operations when calculating SAD.\n- The `load_images` function loads images from the specified file paths, while the `calculate_sad` function computes the SAD and the `display_results` function shows the results to the user. \n- The TODO comments indicate where the implementation details will be added by the development teams.",
        "answer": "'''\nDisplay the calculated SAD value for the user.\nARGUMENTS:\n- sad_value: float - The calculated sum of absolute differences between the two images.\nRETURN: None\n'''\ndef display_results(sad_value: float) -> None:\n    print(\"The calculated Sum of Absolute Differences (SAD) between the two images is: {:.2f}\".format(sad_value))"
    },
    {
        "requirement": "def COMPUTE_NCC(input_image: np.ndarray, reference_image: np.ndarray) -> np.ndarray:\n    '''\n    Implements the algorithm to calculate the normalized cross-correlation values between the preprocessed images.\n    \n    ARGUMENTS:\n    - input_image: np.ndarray - The preprocessed input image.\n    - reference_image: np.ndarray - The preprocessed reference image.\n    \n    RETURN: np.ndarray - Normalized cross-correlation values.\n    '''\n    # Calculate the mean of both images\n    input_mean = np.mean(input_image)\n    reference_mean = np.mean(reference_image)\n\n    # Subtract the mean from each image to get the zero-mean images\n    input_zero_mean = input_image - input_mean\n    reference_zero_mean = reference_image - reference_mean\n\n    # Compute the NCC\n    numerator = np.sum(input_zero_mean * reference_zero_mean)\n    denominator = np.sqrt(np.sum(input_zero_mean ** 2) * np.sum(reference_zero_mean ** 2))\n    \n    ncc_value = numerator / denominator if denominator != 0 else 0\n\n    return ncc_value\n",
        "answer": "'''\nImplements the algorithm to calculate the normalized cross-correlation values between the preprocessed images.\n\nARGUMENTS:\n- input_image: np.ndarray - The preprocessed input image.\n- reference_image: np.ndarray - The preprocessed reference image.\n\nRETURN: np.ndarray - Normalized cross-correlation values.\n'''\nimport numpy as np\n\ndef COMPUTE_NCC(input_image: np.ndarray, reference_image: np.ndarray) -> np.ndarray:\n    # Calculate the mean of both images\n    input_mean = np.mean(input_image)\n    reference_mean = np.mean(reference_image)\n\n    # Subtract the mean from each image to get the zero-mean images\n    input_zero_mean = input_image - input_mean\n    reference_zero_mean = reference_image - reference_mean\n\n    # Compute the NCC\n    numerator = np.sum(input_zero_mean * reference_zero_mean)\n    denominator = np.sqrt(np.sum(input_zero_mean ** 2) * np.sum(reference_zero_mean ** 2))\n\n    ncc_value = numerator / denominator if denominator != 0 else 0\n\n    return ncc_value"
    },
    {
        "requirement": "def label_connected_components(binary_image: np.ndarray) -> np.ndarray:\n    '''\n    Implement the algorithm to traverse and label connected pixels in the image using 4-connectivity.\n    ARGUMENTS: binary_image (np.ndarray) - The binary image for labeling connected components.\n    RETURN: np.ndarray - The labeled image with distinct components.\n    '''\n    import cv2\n    # TODO: Use cv2.connectedComponents to label the connected components.\n    num_labels, labeled_image = cv2.connectedComponents(binary_image)\n    return labeled_image\n",
        "answer": "'''\nImplement the algorithm to traverse and label connected pixels in the image using 4-connectivity.\nARGUMENTS: binary_image (np.ndarray) - The binary image for labeling connected components.\nRETURN: np.ndarray - The labeled image with distinct components.\n'''\nimport numpy as np\nimport cv2\n\ndef label_connected_components(binary_image: np.ndarray) -> np.ndarray:\n    num_labels, labeled_image = cv2.connectedComponents(binary_image)\n    return labeled_image"
    },
    {
        "requirement": "def display_labeled_image(labeled_image: np.ndarray, output_path: str):\n    '''\n    Display or save the labeled image for visualization of the connected components.\n    ARGUMENTS: labeled_image (np.ndarray) - The labeled image to be displayed or saved.\n               output_path (str) - The path where to save the labeled image.\n    RETURN: None\n    '''\n    import cv2\n    # TODO: Use cv2.imshow to display the image, and cv2.imwrite to save it to the specified path.\n    cv2.imshow(\"Labeled Image\", labeled_image)\n    cv2.imwrite(output_path, labeled_image)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n```\n\n### External Libraries Used:\n- `cv2`: This is OpenCV, a library used for computer vision tasks including image processing.\n- `numpy`: This library is implied in the function signatures as it is commonly used with OpenCV images, although it was not explicitly mentioned for import since it's a standard library and may be imported globally in the project. \n\nPlease proceed with delegating these functions to the Development Groups.",
        "answer": "'''\nDisplay or save the labeled image for visualization of the connected components.\nARGUMENTS: labeled_image (np.ndarray) - The labeled image to be displayed or saved.\n           output_path (str) - The path where to save the labeled image.\nRETURN: None\n'''\ndef display_labeled_image(labeled_image: np.ndarray, output_path: str):\n    import cv2\n    # Display the image in a window\n    cv2.imshow(\"Labeled Image\", labeled_image)\n    # Save the image to the specified path\n    cv2.imwrite(output_path, labeled_image)\n    # Wait for a key press and close the window\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()"
    },
    {
        "requirement": "def label_connected_components(image: np.ndarray) -> np.ndarray:\n    '''\n    This function implements the core algorithm for Connected Component Labeling \n    using 8-connectivity. It identifies connected components in the processed image \n    and assigns unique labels to each component.\n    \n    ARGUMENTS: \n    image: np.ndarray - The binary image on which labeling will be performed.\n\n    RETURN: np.ndarray - The labeled image with unique identifiers for each component.\n    '''\n    # TODO: Implement the connected component labeling algorithm using 8-connectivity\n    num_labels, labeled_image = cv2.connectedComponents(image, connectivity=8)\n    return labeled_image\n",
        "answer": "'''\nThis function implements the core algorithm for Connected Component Labeling \nusing 8-connectivity. It identifies connected components in the processed image \nand assigns unique labels to each component.\n\nARGUMENTS: \nimage: np.ndarray - The binary image on which labeling will be performed.\n\nRETURN: np.ndarray - The labeled image with unique identifiers for each component.\n'''\nimport numpy as np\nimport cv2\n\ndef label_connected_components(image: np.ndarray) -> np.ndarray:\n    num_labels, labeled_image = cv2.connectedComponents(image, connectivity=8)\n    return labeled_image"
    },
    {
        "requirement": "def run_connected_component_labeling(input_image_path: str, output_image_path: str) -> None:\n    '''\n    This function orchestrates the overall process by calling the above functions in sequence.\n    \n    ARGUMENTS: \n    input_image_path: str - The path to the input image file.\n    output_image_path: str - The path where the output labeled image will be saved.\n\n    RETURN: None\n    '''\n    # TODO: Implement the overall execution flow of labeling connected components\n    image = read_image(input_image_path)\n    processed_image = process_image(image)\n    labeled_image = label_connected_components(processed_image)\n    save_labeled_image(labeled_image, output_image_path)\n```\n\nThese definitions include the necessary libraries and a structured format for each function, outlining their responsibilities and expected arguments and return types.",
        "answer": "'''\nThis function orchestrates the overall process by calling the above functions in sequence.\n\nARGUMENTS: \ninput_image_path: str - The path to the input image file.\noutput_image_path: str - The path where the output labeled image will be saved.\n\nRETURN: None\n'''\ndef run_connected_component_labeling(input_image_path: str, output_image_path: str) -> None:\n    image = read_image(input_image_path)\n    processed_image = process_image(image)\n    labeled_image = label_connected_components(processed_image)\n    save_labeled_image(labeled_image, output_image_path)"
    },
    {
        "requirement": "def apply_alpha_blending(image1: np.ndarray, image2: np.ndarray, alpha: float):\n    '''\n    Implement the alpha blending algorithm based on the provided equation \n    (alpha * image1 + (1 - alpha) * image2).\n    \n    ARGUMENTS:\n    image1: np.ndarray - The first image as a NumPy array.\n    image2: np.ndarray - The second image as a NumPy array.\n    alpha: float - The blending factor (0.0 <= alpha <= 1.0).\n    \n    RETURN: np.ndarray - The blended image as a NumPy array.\n    '''\n    # Ensure the images are of the same size\n    if image1.shape != image2.shape:\n        raise ValueError(\"Images must be of the same dimensions for blending.\")\n    \n    # Apply the alpha blending formula\n    blended_image = alpha * image1 + (1 - alpha) * image2\n    \n    # Ensure the pixel values are within the valid range\n    blended_image = np.clip(blended_image, 0, 255).astype(np.uint8)\n    \n    return blended_image\n",
        "answer": "'''\nImplement the alpha blending algorithm based on the provided equation \n(alpha * image1 + (1 - alpha) * image2).\n\nARGUMENTS:\nimage1: np.ndarray - The first image as a NumPy array.\nimage2: np.ndarray - The second image as a NumPy array.\nalpha: float - The blending factor (0.0 <= alpha <= 1.0).\n\nRETURN: np.ndarray - The blended image as a NumPy array.\n'''\ndef apply_alpha_blending(image1: np.ndarray, image2: np.ndarray, alpha: float):\n    # Ensure the images are of the same size\n    if image1.shape != image2.shape:\n        raise ValueError(\"Images must be of the same dimensions for blending.\")\n    \n    # Apply the alpha blending formula\n    blended_image = alpha * image1 + (1 - alpha) * image2\n    \n    # Ensure the pixel values are within the valid range\n    blended_image = np.clip(blended_image, 0, 255).astype(np.uint8)\n    \n    return blended_image"
    }
]